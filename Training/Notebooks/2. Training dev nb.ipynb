{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Training dev nb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VimalMollyn/ED6001-Term-Project/blob/colab/Training/Notebooks/2.%20Training%20dev%20nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv1VVaDjK1ec",
        "outputId": "2c2a3f25-6e1e-4418-852e-b7d937127049"
      },
      "source": [
        "## stuff to include at the start of each notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone -b colab https://github.com/VimalMollyn/ED6001-Term-Project.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'ED6001-Term-Project'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 135 (delta 60), reused 52 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (135/135), 9.68 MiB | 22.99 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausM4SOo-kck"
      },
      "source": [
        "# !rm -r /content/ED6001-Term-Project/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KfRJ8JOMDOh",
        "outputId": "0a246e8e-eba6-4b34-9964-25ed85e1b4fe"
      },
      "source": [
        "!conda install scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs9QqrGmL7vP"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'ED6001-Term-Project/Training/')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hov55xbhLfyY"
      },
      "source": [
        "## imports go here\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity, normalized_root_mse\n",
        "\n",
        "from preprocessing import patch_test_img, merge_test_img\n",
        "# from data import MRIDataset ## imports for the MRI dataset\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "class GeneratorNet(nn.Module):\n",
        "    \"\"\" \n",
        "    In the original implementation, post-activation values were being added to pre-activation values \n",
        "    Modified it to add pre-activation values, then apply activation\n",
        "    Removed final ReLU\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv3d(1, 32, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(32),)\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.LeakyReLU(inplace=True), nn.Conv3d(32, 64, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(64),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.LeakyReLU(inplace=True), nn.Conv3d(64, 128, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(128),\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.LeakyReLU(inplace=True), nn.Conv3d(128, 256, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(256),\n",
        "        )\n",
        "\n",
        "        self.deConv1 = nn.Sequential(\n",
        "            nn.LeakyReLU(inplace=True), nn.Conv3d(256, 128, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(128),\n",
        "        )\n",
        "\n",
        "        self.deConv2 = nn.Sequential(\n",
        "            nn.LeakyReLU(inplace=True), nn.Conv3d(128, 64, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(64),\n",
        "        )\n",
        "\n",
        "        self.deConv3 = nn.Sequential(\n",
        "            nn.LeakyReLU(inplace=True), nn.Conv3d(64, 32, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(32),\n",
        "        )\n",
        "\n",
        "        self.deConv4 = nn.Sequential(nn.LeakyReLU(inplace=True), nn.Conv3d(32, 1, kernel_size=3, padding=1),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "        conv4 = self.conv4(conv3)\n",
        "\n",
        "        out = self.deConv1(conv4)\n",
        "        out += conv3\n",
        "\n",
        "        out = self.deConv2(out)\n",
        "        out += conv2\n",
        "\n",
        "        out = self.deConv3(out)\n",
        "        out += conv1\n",
        "\n",
        "        out = self.deConv4(out)\n",
        "        out += x\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class DiscriminatorNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv3d(1, 32, kernel_size=3, padding=1), nn.LeakyReLU(),)\n",
        "\n",
        "        self.conv2 = nn.Sequential(nn.Conv3d(32, 64, kernel_size=3, padding=1), nn.LeakyReLU(),)\n",
        "\n",
        "        self.conv3 = nn.Sequential(nn.Conv3d(64, 128, kernel_size=3, padding=1), nn.LeakyReLU(),)\n",
        "\n",
        "        self.fc = nn.Linear(128 * 6 * 32 * 32, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for i in size:\n",
        "            num_features *= i\n",
        "\n",
        "        return num_features\n",
        "\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG19, self).__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True)\n",
        "        self.feature = vgg19.features\n",
        "    '''\n",
        "    input: N*1*D(6)*H*W\n",
        "    output: N*C*H*W\n",
        "    '''\n",
        "\n",
        "    def forward(self, input):\n",
        "        # VGG19: means:103.939, 116.779, 123.68\n",
        "        input /= 16\n",
        "        depth = input.size()[2]\n",
        "        result = []\n",
        "        for i in range(depth):\n",
        "            x = torch.cat(\n",
        "                (input[:, :, i, :, :] - 103.939, input[:, :, i, :, :] - 116.779, input[:, :, i, :, :] - 123.68), 1)\n",
        "            result.append(self.feature(x))\n",
        "\n",
        "        output = torch.cat(result, dim=1)\n",
        "\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohdln8DRMoJW"
      },
      "source": [
        "def initialize_weights(*models):\n",
        "    for model in models:\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Conv3d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm3d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8BYcjNmOLO_"
      },
      "source": [
        "class WGAN():\n",
        "    def __init__(self, level=0):\n",
        "        # parameters\n",
        "        self.epochs = 10\n",
        "        self.batch_size = 110\n",
        "        self.lr =5e-6\n",
        "\n",
        "        self.d_iter = 5\n",
        "        self.lambda_gp = 10\n",
        "\n",
        "        self.lambda_vgg = 1e-1\n",
        "        self.lambda_d = 1e-3\n",
        "        self.lambda_mse = 1\n",
        "\n",
        "        self.level = level\n",
        "\n",
        "        self.loss_dir = \"./loss/\"\n",
        "        self.v = \"0_0_5_%d\" % self.level  # vs\n",
        "        self.save_dir = \"./model/\" + self.v + \"/\"\n",
        "        Path(self.loss_dir).mkdir(parents=True, exist_ok=True)\n",
        "        Path(self.save_dir).mkdir(parents=True, exist_ok=True)\n",
        "        self.gpu = False\n",
        "\n",
        "        self.generator = GeneratorNet()\n",
        "        self.discriminator = DiscriminatorNet()\n",
        "        self.vgg19 = VGG19()\n",
        "\n",
        "        self.G_optimizer = optim.Adam(\n",
        "            self.generator.parameters(), lr=self.lr, betas=(0.5, 0.9))\n",
        "        self.D_optimizer = optim.Adam(\n",
        "            self.discriminator.parameters(), lr=self.lr, betas=(0.5, 0.9))\n",
        "\n",
        "        self.G_loss = nn.MSELoss()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.generator.cuda()\n",
        "            self.discriminator.cuda()\n",
        "            self.vgg19.cuda()\n",
        "            self.gpu = True\n",
        "        if not self.load_model():\n",
        "            initialize_weights(self.generator)\n",
        "            initialize_weights(self.discriminator)\n",
        "\n",
        "    def train(self, trainloader, validloader):\n",
        "        self.dataloader = trainloader\n",
        "        self.validDataloader = validloader\n",
        "\n",
        "        ## training loop\n",
        "        for epoch in range(0, self.epochs):\n",
        "            # self.test(epoch)\n",
        "            # iterate over the dataset\n",
        "            for batch_index, batch in enumerate(self.dataloader):\n",
        "\n",
        "                clean_img = batch[\"clean_img\"]\n",
        "                noised_img = batch[\"noisy_img\"]\n",
        "\n",
        "                # train discriminator\n",
        "                for iter_i in range(self.d_iter):\n",
        "                    loss = self._train_discriminator(clean_img, noised_img)\n",
        "                    print(\"\\tVGG_MSE - lr: %.10f, Level: %d, Epoch: %d, bath_index: %d, iter: %d, G-Loss: \" %\n",
        "                          (self.lr, self.level, epoch, batch_index, iter_i), loss)\n",
        "\n",
        "                # train generator\n",
        "                loss = self._train_generator(clean_img, noised_img)\n",
        "\n",
        "                # save model and loss\n",
        "                if batch_index % 100 == 0:\n",
        "                    self.save_model()\n",
        "\n",
        "\n",
        "            if ((epoch + 1) % 4 == 0 and self.lr > 1e-7):\n",
        "                self.G_optimizer.defaults[\"lr\"] *= 0.5\n",
        "                self.G_optimizer.defaults[\"lr\"] *= 0.5\n",
        "                self.lr *= 0.5\n",
        "\n",
        "    def _train_discriminator(self, clean_img, noised_img, train=True):\n",
        "        self.D_optimizer.zero_grad()\n",
        "\n",
        "        z = Variable(noised_img)\n",
        "        real_img = Variable(clean_img / 4096)\n",
        "        if self.gpu:\n",
        "            z = z.cuda()\n",
        "            real_img = real_img.cuda()\n",
        "\n",
        "        fake_img = self.generator(z)\n",
        "        real_validity = self.discriminator(real_img)\n",
        "        fake_validity = self.discriminator(fake_img.data / 4096)\n",
        "        gradient_penalty = self._calc_gradient_penalty(\n",
        "            real_img.data, fake_img.data)\n",
        "\n",
        "        d_loss = torch.mean(-real_validity) + torch.mean(fake_validity) + \\\n",
        "            self.lambda_gp * gradient_penalty\n",
        "        if train:\n",
        "            d_loss.backward()\n",
        "            self.D_optimizer.step()\n",
        "\n",
        "        return d_loss.data.item(), torch.mean(-real_validity).cpu().item(), torch.mean(fake_validity).cpu().item(), self.lambda_gp * gradient_penalty.cpu().item()\n",
        "\n",
        "    def _train_generator(self, clean_img, noised_img, train=True):\n",
        "        z = Variable(noised_img)\n",
        "        real_img = Variable(clean_img, requires_grad=False)\n",
        "\n",
        "\n",
        "        if self.gpu:\n",
        "            z = z.cuda()\n",
        "            real_img = real_img.cuda()\n",
        "\n",
        "        self.G_optimizer.zero_grad()\n",
        "        self.D_optimizer.zero_grad()\n",
        "        self.vgg19.zero_grad()\n",
        "\n",
        "        criterion_mse = nn.MSELoss()\n",
        "        criterion_vgg= nn.MSELoss()\n",
        "\n",
        "        fake_img = self.generator(z)\n",
        "        mse_loss = criterion_mse(fake_img, real_img)\n",
        "        if train:\n",
        "            (self.lambda_mse * mse_loss).backward(retain_graph=True)\n",
        "\n",
        "\n",
        "        feature_fake_vgg = self.vgg19(fake_img)\n",
        "        feature_real_vgg = Variable(self.vgg19(real_img).data, requires_grad=False).cuda()\n",
        "\n",
        "        vgg_loss = criterion_vgg(feature_fake_vgg, feature_real_vgg)\n",
        "\n",
        "        fake_validity = self.discriminator(fake_img / 4096)\n",
        "        g_loss =  self.lambda_vgg * vgg_loss + self.lambda_d * torch.mean(-fake_validity)\n",
        "\n",
        "        if train:\n",
        "            g_loss.backward()\n",
        "            self.G_optimizer.step()\n",
        "        return g_loss.data.item(), mse_loss.data.item(), torch.mean(-fake_validity).data.item(), vgg_loss.data.item()\n",
        "\n",
        "    def _calc_gradient_penalty(self, clean_img, gen_img):\n",
        "        batch_size = clean_img.size()[0]\n",
        "        alpha = Variable(torch.rand(batch_size, 1))\n",
        "        alpha = alpha.expand(batch_size, clean_img.nelement(\n",
        "        ) // batch_size).contiguous().view(clean_img.size()).float()\n",
        "        if self.gpu:\n",
        "            alpha = alpha.cuda()\n",
        "\n",
        "        interpolates = (alpha * clean_img + (1 - alpha)\n",
        "                        * gen_img).requires_grad_(True)\n",
        "        disc_interpolates = self.discriminator(interpolates)\n",
        "        fake = Variable(torch.Tensor(batch_size, 1).fill_(1.0),\n",
        "                        requires_grad=False)\n",
        "        if self.gpu:\n",
        "            fake = fake.cuda()\n",
        "\n",
        "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                  grad_outputs=fake, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        return gradient_penalty\n",
        "\n",
        "    def test(self, epoch):\n",
        "        timestr = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "        print(timestr)\n",
        "\n",
        "        # test set\n",
        "        total_mse_loss = 0\n",
        "        total_g_loss = 0\n",
        "        total_d_loss = 0\n",
        "        total_vgg_loss = 0\n",
        "        batch_num = 0\n",
        "        for batch_index, batch in enumerate(self.validDataloader):\n",
        "            clean_img = batch[\"clean_img\"]\n",
        "            noisy_img = batch[\"noisy_img\"]\n",
        "\n",
        "            loss = self._train_generator(clean_img, noisy_img, train=False)\n",
        "            total_g_loss += loss[0]\n",
        "            total_mse_loss += loss[1]\n",
        "            total_d_loss += loss[2]\n",
        "            total_vgg_loss += loss[3]\n",
        "            batch_num += 1\n",
        "        mse_loss = total_mse_loss / batch_num\n",
        "        g_loss = total_g_loss / batch_num\n",
        "        d_loss = total_d_loss / batch_num\n",
        "        vgg_loss = total_vgg_loss / batch_num\n",
        "        print(\"%s Epoch： %d lr：%.10f Test Loss：g-loss: %.4f vgg-loss: %.4f mse-loss： %.4f d_loss: %.4f\" %\n",
        "                (self.v, epoch, self.G_optimizer.defaults[\"lr\"], g_loss, vgg_loss, mse_loss, d_loss))\n",
        "        # self.compute_quality()\n",
        "        self.save_loss((vgg_loss, mse_loss, g_loss, d_loss))\n",
        "        self.save_model()\n",
        "\n",
        "    def compute_quality(self):\n",
        "        psnr1 = 0\n",
        "        psnr2 = 0\n",
        "        mse1 = 0\n",
        "        mse2 = 0\n",
        "        ssim1 = 0\n",
        "        ssim2 = 0\n",
        "        _psnr1 = 0\n",
        "        _psnr2 = 0\n",
        "        _mse1 = 0\n",
        "        _mse2 = 0\n",
        "        _ssim1 = 0\n",
        "        _ssim2 = 0\n",
        "\n",
        "        for i in range(101, 111):\n",
        "            free_nii = nib.load(\"./data/dataset/Free/%d.nii\" % i)\n",
        "            noised_nii = nib.load(\n",
        "                \"./data/dataset/noise_%d/%d.nii\" % (self.level, i))\n",
        "\n",
        "            clean_img = free_nii.get_data()[:, :144, :].astype(np.int16)\n",
        "            noisy_img = noised_nii.get_data()[:, :144, :].astype(np.int16)\n",
        "            patchs, row, col = patch_test_img(noisy_img)\n",
        "            denoisy_img = merge_test_img(\n",
        "                self.denoising(patchs), row, col).astype(np.int16)\n",
        "\n",
        "            psnr1 += peak_signal_noise_ratio(clean_img, noisy_img, 4096)\n",
        "            psnr2 += peak_signal_noise_ratio(clean_img, denoisy_img, 4096)\n",
        "\n",
        "            mse1 += normalized_root_ms(clean_img, noisy_img)\n",
        "            mse2 += normalized_root_ms(clean_img, denoisy_img)\n",
        "\n",
        "            ssim1 += structural_similarity(clean_img, noisy_img,\n",
        "                                  data_range=4096, multichannel=True)\n",
        "            ssim2 += structural_similarity(clean_img, denoisy_img,\n",
        "                                  data_range=4096, multichannel=True)\n",
        "\n",
        "            max = np.max(clean_img)\n",
        "            _psnr1 += peak_signal_noise_ratio(clean_img, noisy_img, max)\n",
        "            _psnr2 += peak_signal_noise_ratio(clean_img, denoisy_img, max)\n",
        "\n",
        "            _mse1 += normalized_root_ms(clean_img, noisy_img)\n",
        "            _mse2 += normalized_root_ms(clean_img, denoisy_img)\n",
        "\n",
        "            _ssim1 += structural_similarity(clean_img, noisy_img,\n",
        "                                   data_range=max, multichannel=True)\n",
        "            _ssim2 += structural_similarity(clean_img, denoisy_img,\n",
        "                                   data_range=max, multichannel=True)\n",
        "            \n",
        "        psnr1 *= 0.1\n",
        "        psnr2 *= 0.1\n",
        "        mse1 *= 0.1\n",
        "        mse2 *= 0.1\n",
        "        ssim1 *= 0.1\n",
        "        ssim2 *= 0.1\n",
        "\n",
        "        _psnr1 *= 0.1\n",
        "        _psnr2 *= 0.1\n",
        "        _mse1 *= 0.1\n",
        "        _mse2 *= 0.1\n",
        "        _ssim1 *= 0.1\n",
        "        _ssim2 *= 0.1\n",
        "        with open(\"./loss/\" + self.v + \"psnr.csv\", \"a+\") as f:\n",
        "            f.write(\"%f,%f,%f,%f,%f,%f\\n\" %\n",
        "                    (_psnr1, _psnr2, _ssim1, _ssim2, _mse1, _mse2))\n",
        "        timestr = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "        with open(\"./loss/\" + self.v + \"psnr_4096.csv\", \"a+\") as f:\n",
        "            f.write(\"%s: %.10f,%f,%f,%f,%f,%f,%f\\n\" %\n",
        "                    (timestr, self.lr, psnr1, psnr2, ssim1, ssim2, mse1, mse2))\n",
        "        print(\"psnr: %f,%f,ssim: %f,%f,mse:%f,%f\\n\" %\n",
        "              (_psnr1, _psnr2, _ssim1, _ssim2, _mse1, _mse2))\n",
        "\n",
        "    '''\n",
        "    N*H*W*D -> N*C*D*H*W\n",
        "    return: N*H*W*D\n",
        "    '''\n",
        "\n",
        "    def denoising(self, patchs):\n",
        "        n, h, w, d = patchs.shape\n",
        "        denoised_patchs = []\n",
        "        for i in range(0, n, self.batch_size):\n",
        "            batch = patchs[i:i + self.batch_size]\n",
        "            batch_size = batch.shape[0]\n",
        "            x = np.reshape(batch, (batch_size, 1, w, h, d))\n",
        "            x = x.transpose(0, 1, 4, 2, 3)\n",
        "            x = Variable(torch.from_numpy(x).float()).cuda()\n",
        "            y = self.generator(x)\n",
        "            denoised_patchs.append(y.cpu().data.numpy())\n",
        "\n",
        "        denoised_patchs = np.vstack(denoised_patchs)\n",
        "        denoised_patchs = np.reshape(denoised_patchs, (n, d, h, w))\n",
        "        denoised_patchs = denoised_patchs.transpose(0, 2, 3, 1)\n",
        "        return denoised_patchs\n",
        "\n",
        "    def save_model(self):\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.makedirs(self.save_dir)\n",
        "        torch.save(self.generator.state_dict(),\n",
        "                   self.save_dir + \"G_\" + self.v + \".pkl\")\n",
        "        torch.save(self.discriminator.state_dict(),\n",
        "                   self.save_dir + \"D_\" + self.v + \".pkl\")\n",
        "\n",
        "    def load_model(self):\n",
        "        if os.path.exists(self.save_dir + \"G_\" + self.v + \".pkl\") and \\\n",
        "                os.path.exists(self.save_dir + \"D_\" + self.v + \".pkl\"):\n",
        "\n",
        "            self.generator.load_state_dict(\n",
        "                torch.load(self.save_dir + \"G_\" + self.v + \".pkl\")\n",
        "            )\n",
        "            self.discriminator.load_state_dict(\n",
        "                torch.load(self.save_dir + \"D_\" + self.v + \".pkl\"\n",
        "            )\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def save_loss(self, loss):\n",
        "        value = \"\"\n",
        "        for item in loss:\n",
        "            value = value + str(item) + \",\"\n",
        "        value += \"\\n\"\n",
        "        with open(\"./loss/\" + self.v + \".csv\", \"a+\") as f:\n",
        "            f.write(value)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sVTpfdIEtpe"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import numpy as np\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, path_to_data, split=\"train\"):\n",
        "        if split == \"train\":\n",
        "            split_indices = [*range(1, 101)]\n",
        "        elif split == \"test\":\n",
        "            split_indices = [*range(101, 111)]\n",
        "\n",
        "        print(f\"Start reading {split}ing dataset...\")\n",
        "\n",
        "        # read the first set of volumes\n",
        "        clean_mri_set = []\n",
        "        noisy_mri_set = []\n",
        "\n",
        "        for i in tqdm_notebook(split_indices):\n",
        "            # load the current volumes\n",
        "            clean_mri_temp = np.load(path_to_data / f\"data/{i}.npy\")\n",
        "            noisy_mri_temp = np.load(path_to_data / f\"noisy/{i}.npy\")\n",
        "\n",
        "            # append to the existing stack\n",
        "            clean_mri_set.append(clean_mri_temp)\n",
        "            noisy_mri_set.append(noisy_mri_temp)\n",
        "\n",
        "        self.clean_mri_set = clean_mri_set\n",
        "        self.noisy_mri_set = noisy_mri_set\n",
        "        self.arrshape0 = clean_mri_set[0].shape[0]\n",
        "        self.total = len(self.clean_mri_set) * self.arrshape0\n",
        "        self.current_patch = 1\n",
        "\n",
        "        print(len(self.clean_mri_set))\n",
        "        print(self.total)\n",
        "        print(f\"End reading {split}ing dataset...\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = index // self.arrshape0\n",
        "        y = index % self.arrshape0\n",
        "        clean_img = torch.from_numpy(self.clean_mri_set[x][y]).float().squeeze(axis=1)\n",
        "        noisy_img = torch.from_numpy(self.noisy_mri_set[x][y]).float().squeeze(axis=1)\n",
        "        return {\"clean_img\": clean_img, \"noisy_img\": noisy_img}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XxhAkmqoO0C9",
        "outputId": "c003f1c8-b4a5-4600-9cc3-b06be1ef2f29"
      },
      "source": [
        "path_to_data = Path(\"/content/drive/MyDrive/ED6001_MIA_Term_Project/patches\")\n",
        "wgan = WGAN()\n",
        "\n",
        "# trainset = MRIDataset(path_to_data=path_to_data, split=\"train\")\n",
        "# trainloader = DataLoader(trainset, batch_size=wgan.batch_size, shuffle=True)\n",
        "# validset = MRIDataset(path_to_data=path_to_data, split=\"test\")\n",
        "# validloader = DataLoader(validset, batch_size=wgan.batch_size, shuffle=True)\n",
        "\n",
        "with torch.autograd.set_detect_anomaly(True):\n",
        "    wgan.train(trainloader, validloader)\n",
        "\n",
        "    # # valid\n",
        "    # for i in range(101, 111):\n",
        "\n",
        "    #     nii_img = nib.load(\"./data/dataset/noise_%d/%d.nii\" % (level, i))\n",
        "    #     x = nii_img.get_data()\n",
        "    #     patchs, row, col = patch_test_img(x)\n",
        "    #     print(patchs.shape)\n",
        "    #     denoised_img = merge_test_img(wgan.denoising(patchs), row, col)\n",
        "    #     print(denoised_img.shape)\n",
        "    #     denoised_img = denoised_img.astype(np.int16)\n",
        "\n",
        "    #     denoised_image = nib.Nifti1Image(\n",
        "    #         denoised_img, nii_img.affine, nii_img.header)\n",
        "    #     nib.save(denoised_image, \"./result/%d_wgan_vgg_mse_denoised_img%d.nii\" % (level, i))\n",
        "    # # print((x - denoised_img).mean())\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 0, G-Loss:  (9.781770706176758, 0.019236819818615913, -0.01475350558757782, 9.7772878408432)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 1, G-Loss:  (9.736896514892578, 0.11155910044908524, -0.15187031030654907, 9.777207374572754)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 2, G-Loss:  (9.691872596740723, 0.20403920114040375, -0.28919732570648193, 9.777030944824219)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 3, G-Loss:  (9.646605491638184, 0.2969087064266205, -0.42705950140953064, 9.776756167411804)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 4, G-Loss:  (9.600995063781738, 0.3904128074645996, -0.5657995939254761, 9.776381850242615)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 1, iter: 0, G-Loss:  (9.51644229888916, 0.4151609539985657, -0.6751509308815002, 9.776432514190674)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 1, iter: 1, G-Loss:  (9.457104682922363, 0.5043709874153137, -0.8231299519538879, 9.775863885879517)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 1, iter: 2, G-Loss:  (9.396109580993652, 0.5958130955696106, -0.9749274253845215, 9.775223731994629)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 1, iter: 3, G-Loss:  (9.334383010864258, 0.6882622838020325, -1.1283503770828247, 9.774470925331116)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 1, iter: 4, G-Loss:  (9.272207260131836, 0.7814282178878784, -1.2828515768051147, 9.77363109588623)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 2, iter: 0, G-Loss:  (9.279744148254395, 0.8661012053489685, -1.3586515188217163, 9.772294163703918)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 2, iter: 1, G-Loss:  (9.225066184997559, 0.9553296566009521, -1.5015665292739868, 9.771302938461304)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 2, iter: 2, G-Loss:  (9.170273780822754, 1.0434701442718506, -1.6434577703475952, 9.770262241363525)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 2, iter: 3, G-Loss:  (9.115078926086426, 1.1317533254623413, -1.7857937812805176, 9.769119620323181)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 2, iter: 4, G-Loss:  (9.05927848815918, 1.2209166288375854, -1.9295148849487305, 9.767876267433167)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 3, iter: 0, G-Loss:  (9.058014869689941, 1.2952734231948853, -2.0043869018554688, 9.767128229141235)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 3, iter: 1, G-Loss:  (9.004886627197266, 1.3849704265594482, -2.1458981037139893, 9.765814542770386)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 3, iter: 2, G-Loss:  (8.950777053833008, 1.4753576517105103, -2.2890169620513916, 9.764437079429626)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 3, iter: 3, G-Loss:  (8.895801544189453, 1.5668436288833618, -2.4340128898620605, 9.762970805168152)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 3, iter: 4, G-Loss:  (8.839972496032715, 1.6597689390182495, -2.5812246799468994, 9.761428236961365)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 4, iter: 0, G-Loss:  (8.526973724365234, 2.065786361694336, -3.2990472316741943, 9.760234951972961)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 4, iter: 1, G-Loss:  (8.448020935058594, 2.191988945007324, -3.502422332763672, 9.758453965187073)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 4, iter: 2, G-Loss:  (8.364874839782715, 2.323930501937866, -3.7155728340148926, 9.75651741027832)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 4, iter: 3, G-Loss:  (8.279973983764648, 2.4585442543029785, -3.933084726333618, 9.754514694213867)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 4, iter: 4, G-Loss:  (8.194228172302246, 2.5946102142333984, -4.1528215408325195, 9.752439260482788)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 5, iter: 0, G-Loss:  (8.156505584716797, 2.5088672637939453, -4.102163314819336, 9.749801754951477)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 5, iter: 1, G-Loss:  (8.071769714355469, 2.6358799934387207, -4.311642646789551, 9.747532606124878)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 5, iter: 2, G-Loss:  (7.98615837097168, 2.7629787921905518, -4.522038459777832, 9.745218753814697)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 5, iter: 3, G-Loss:  (7.900065898895264, 2.890584945678711, -4.733378887176514, 9.742860198020935)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 5, iter: 4, G-Loss:  (7.813441276550293, 3.018864870071411, -4.945763111114502, 9.740339517593384)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 6, iter: 0, G-Loss:  (8.182197570800781, 3.663003444671631, -5.2188262939453125, 9.738020300865173)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 6, iter: 1, G-Loss:  (8.119192123413086, 3.7991020679473877, -5.4154767990112305, 9.735566973686218)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 6, iter: 2, G-Loss:  (8.057332038879395, 3.929349899291992, -5.605133056640625, 9.733115434646606)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 6, iter: 3, G-Loss:  (7.995630264282227, 4.058079719543457, -5.793150901794434, 9.730701446533203)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 6, iter: 4, G-Loss:  (7.933349132537842, 4.187610626220703, -5.982410907745361, 9.728149771690369)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 7, iter: 0, G-Loss:  (7.465219020843506, 3.5146970748901367, -5.774852275848389, 9.725374579429626)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 7, iter: 1, G-Loss:  (7.380983352661133, 3.6373891830444336, -5.978845596313477, 9.722439646720886)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 7, iter: 2, G-Loss:  (7.291921615600586, 3.7671518325805664, -6.19459342956543, 9.71936285495758)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 7, iter: 3, G-Loss:  (7.200427055358887, 3.9004509449005127, -6.416130065917969, 9.716106653213501)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 7, iter: 4, G-Loss:  (7.107640266418457, 4.035820960998535, -6.640973091125488, 9.712792038917542)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 8, iter: 0, G-Loss:  (7.605313301086426, 4.298511028289795, -6.402625560760498, 9.709427952766418)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 8, iter: 1, G-Loss:  (7.537151336669922, 4.428816318511963, -6.597926616668701, 9.70626175403595)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 8, iter: 2, G-Loss:  (7.470142364501953, 4.554284572601318, -6.787112712860107, 9.7029709815979)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 8, iter: 3, G-Loss:  (7.403301239013672, 4.678720951080322, -6.975142955780029, 9.69972312450409)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 8, iter: 4, G-Loss:  (7.335893630981445, 4.803902626037598, -7.1644086837768555, 9.696399569511414)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 9, iter: 0, G-Loss:  (6.2828898429870605, 6.177614688873291, -9.5885591506958, 9.69383418560028)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 9, iter: 1, G-Loss:  (6.17270565032959, 6.363481521606445, -9.880697250366211, 9.689921736717224)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 9, iter: 2, G-Loss:  (6.055178642272949, 6.560629844665527, -10.191179275512695, 9.685727953910828)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 9, iter: 3, G-Loss:  (5.9346842765808105, 6.762881755828857, -10.509550094604492, 9.681352972984314)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 9, iter: 4, G-Loss:  (5.813055992126465, 6.967479705810547, -10.83127212524414, 9.67684805393219)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 10, iter: 0, G-Loss:  (5.879243850708008, 6.630571365356445, -10.422935485839844, 9.671607613563538)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 10, iter: 1, G-Loss:  (5.764166831970215, 6.82066535949707, -10.723575592041016, 9.66707706451416)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 10, iter: 2, G-Loss:  (5.648802757263184, 7.009958267211914, -11.023695945739746, 9.662539958953857)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 10, iter: 3, G-Loss:  (5.53320837020874, 7.199251651763916, -11.323935508728027, 9.657891988754272)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 10, iter: 4, G-Loss:  (5.417382717132568, 7.38898229598999, -11.62478256225586, 9.653183221817017)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 11, iter: 0, G-Loss:  (5.4142303466796875, 6.096071243286133, -10.330779075622559, 9.648938179016113)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 11, iter: 1, G-Loss:  (5.301429271697998, 6.250960826873779, -10.593616485595703, 9.644084572792053)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 11, iter: 2, G-Loss:  (5.187596321105957, 6.406821250915527, -10.858438491821289, 9.639213681221008)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 11, iter: 3, G-Loss:  (5.072919845581055, 6.5636749267578125, -11.124995231628418, 9.63424026966095)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 11, iter: 4, G-Loss:  (4.957465171813965, 6.721433639526367, -11.393158912658691, 9.62918996810913)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 12, iter: 0, G-Loss:  (4.88002347946167, 7.801388263702393, -12.544743537902832, 9.62337851524353)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 12, iter: 1, G-Loss:  (4.764001369476318, 7.982088565826416, -12.836265563964844, 9.618178606033325)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 12, iter: 2, G-Loss:  (4.646547317504883, 8.163103103637695, -13.129493713378906, 9.612937569618225)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 12, iter: 3, G-Loss:  (4.528007507324219, 8.34532356262207, -13.424917221069336, 9.607601165771484)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 12, iter: 4, G-Loss:  (4.4084882736206055, 8.529173851013184, -13.722843170166016, 9.602157473564148)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 13, iter: 0, G-Loss:  (4.536993026733398, 8.028080940246582, -13.088374137878418, 9.597285985946655)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 13, iter: 1, G-Loss:  (4.422911643981934, 8.198131561279297, -13.367005348205566, 9.591785669326782)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 13, iter: 2, G-Loss:  (4.307978630065918, 8.36835765838623, -13.6466064453125, 9.586227536201477)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 13, iter: 3, G-Loss:  (4.192156791687012, 8.539678573608398, -13.92811393737793, 9.580591917037964)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 13, iter: 4, G-Loss:  (4.075366020202637, 8.712700843811035, -14.212215423583984, 9.574880599975586)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 14, iter: 0, G-Loss:  (1.3961830139160156, 10.942922592163086, -19.11570930480957, 9.56896960735321)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 14, iter: 1, G-Loss:  (1.198176383972168, 11.1985502243042, -19.562623977661133, 9.562249779701233)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 14, iter: 2, G-Loss:  (0.9886894226074219, 11.468317031860352, -20.034656524658203, 9.555029273033142)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 14, iter: 3, G-Loss:  (0.7760114669799805, 11.742256164550781, -20.513946533203125, 9.547701478004456)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 14, iter: 4, G-Loss:  (0.5632486343383789, 12.016621589660645, -20.993709564208984, 9.540336728096008)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 15, iter: 0, G-Loss:  (3.097325325012207, 7.690511703491211, -14.126588821411133, 9.53340232372284)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 15, iter: 1, G-Loss:  (2.9641523361206055, 7.843568801879883, -14.406243324279785, 9.526827335357666)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 15, iter: 2, G-Loss:  (2.8378443717956543, 7.98834753036499, -14.671082496643066, 9.520578980445862)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 15, iter: 3, G-Loss:  (2.714029312133789, 8.130143165588379, -14.930608749389648, 9.51449453830719)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 15, iter: 4, G-Loss:  (2.59024715423584, 8.27155876159668, -15.189555168151855, 9.508243203163147)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 16, iter: 0, G-Loss:  (2.868861198425293, 11.860124588012695, -18.493711471557617, 9.502448439598083)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 16, iter: 1, G-Loss:  (2.7520275115966797, 12.055736541748047, -18.799938201904297, 9.496228694915771)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 16, iter: 2, G-Loss:  (2.633951187133789, 12.250017166137695, -19.106029510498047, 9.489963054656982)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 16, iter: 3, G-Loss:  (2.5144290924072266, 12.4456205368042, -19.41484832763672, 9.483656883239746)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 16, iter: 4, G-Loss:  (2.393167495727539, 12.643829345703125, -19.72783088684082, 9.477168917655945)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 17, iter: 0, G-Loss:  (1.9771356582641602, 12.05831527709961, -19.552400588989258, 9.471220970153809)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 17, iter: 1, G-Loss:  (1.8462743759155273, 12.257319450378418, -19.875516891479492, 9.464471936225891)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 17, iter: 2, G-Loss:  (1.711782455444336, 12.46176528930664, -20.207454681396484, 9.457471370697021)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 17, iter: 3, G-Loss:  (1.5748481750488281, 12.670207977294922, -20.54572296142578, 9.450363516807556)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 17, iter: 4, G-Loss:  (1.4359121322631836, 12.881913185119629, -20.889108657836914, 9.4431072473526)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 18, iter: 0, G-Loss:  (1.187516212463379, 15.487814903259277, -23.734954833984375, 9.434655904769897)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 18, iter: 1, G-Loss:  (1.0424118041992188, 15.743648529052734, -24.12845230102539, 9.427215456962585)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 18, iter: 2, G-Loss:  (0.8947610855102539, 16.001628875732422, -24.52655792236328, 9.419690370559692)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 18, iter: 3, G-Loss:  (0.7452392578125, 16.262035369873047, -24.92872428894043, 9.411928057670593)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 18, iter: 4, G-Loss:  (0.5943689346313477, 16.525651931762695, -25.3354434967041, 9.404160380363464)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 19, iter: 0, G-Loss:  (0.5353412628173828, 17.089305877685547, -25.951894760131836, 9.39793050289154)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 19, iter: 1, G-Loss:  (0.38330745697021484, 17.36438751220703, -26.371070861816406, 9.389991164207458)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 19, iter: 2, G-Loss:  (0.2292461395263672, 17.64228630065918, -26.794998168945312, 9.381957650184631)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 19, iter: 3, G-Loss:  (0.07374191284179688, 17.92306137084961, -27.22317123413086, 9.373852014541626)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 19, iter: 4, G-Loss:  (-0.083038330078125, 18.206239700317383, -27.654972076416016, 9.365693926811218)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 20, iter: 0, G-Loss:  (0.2551717758178711, 17.394868850708008, -26.4970760345459, 9.357379078865051)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 20, iter: 1, G-Loss:  (0.10659217834472656, 17.66181182861328, -26.904407501220703, 9.349188208580017)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 20, iter: 2, G-Loss:  (-0.04299354553222656, 17.92915916442871, -27.31307029724121, 9.340918064117432)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 20, iter: 3, G-Loss:  (-0.19369983673095703, 18.198163986206055, -27.724464416503906, 9.332600831985474)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 20, iter: 4, G-Loss:  (-0.34571075439453125, 18.469497680664062, -28.1393985748291, 9.324190616607666)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 21, iter: 0, G-Loss:  (-1.0612564086914062, 17.8421630859375, -28.219263076782227, 9.31584358215332)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 21, iter: 1, G-Loss:  (-1.2278556823730469, 18.114702224731445, -28.649559020996094, 9.307001233100891)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 21, iter: 2, G-Loss:  (-1.398240089416504, 18.392894744873047, -29.08917236328125, 9.298037886619568)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 21, iter: 3, G-Loss:  (-1.5709571838378906, 18.67502784729004, -29.534881591796875, 9.288896918296814)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 21, iter: 4, G-Loss:  (-1.745279312133789, 18.959716796875, -29.984663009643555, 9.279666543006897)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 22, iter: 0, G-Loss:  (-4.168259620666504, 23.173046112060547, -36.61101531982422, 9.269709587097168)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 22, iter: 1, G-Loss:  (-4.393491744995117, 23.544872283935547, -37.19805145263672, 9.259687662124634)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 22, iter: 2, G-Loss:  (-4.626225471496582, 23.92751693725586, -37.8030891418457, 9.249346852302551)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 22, iter: 3, G-Loss:  (-4.861628532409668, 24.31413459777832, -38.41466522216797, 9.23890233039856)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 22, iter: 4, G-Loss:  (-5.097795486450195, 24.702301025390625, -39.02846145629883, 9.228365421295166)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 23, iter: 0, G-Loss:  (-1.3040170669555664, 22.13007926940918, -32.65342712402344, 9.219330549240112)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 23, iter: 1, G-Loss:  (-1.4595203399658203, 22.436681747436523, -33.10610580444336, 9.209904074668884)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 23, iter: 2, G-Loss:  (-1.6081018447875977, 22.7272891998291, -33.536338806152344, 9.200947880744934)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 23, iter: 3, G-Loss:  (-1.7544355392456055, 23.01272201538086, -33.959312438964844, 9.192155003547668)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 23, iter: 4, G-Loss:  (-1.9009714126586914, 23.298681259155273, -34.38295364379883, 9.183301329612732)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 24, iter: 0, G-Loss:  (-1.5109663009643555, 27.702754974365234, -38.38766860961914, 9.173946976661682)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 24, iter: 1, G-Loss:  (-1.6513872146606445, 28.03864860534668, -38.85511779785156, 9.165081977844238)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 24, iter: 2, G-Loss:  (-1.7935409545898438, 28.375083923339844, -39.32479476928711, 9.156169891357422)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 24, iter: 3, G-Loss:  (-1.9376296997070312, 28.71578025817871, -39.800575256347656, 9.147164821624756)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 24, iter: 4, G-Loss:  (-2.0838241577148438, 29.06185531616211, -40.28369140625, 9.138011932373047)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 25, iter: 0, G-Loss:  (-2.760300636291504, 24.15921401977539, -36.04798889160156, 9.128473997116089)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 25, iter: 1, G-Loss:  (-2.9198684692382812, 24.463134765625, -36.50178909301758, 9.118785858154297)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 25, iter: 2, G-Loss:  (-3.083989143371582, 24.77631378173828, -36.9691276550293, 9.108824729919434)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 25, iter: 3, G-Loss:  (-3.251117706298828, 25.09609031677246, -37.44590759277344, 9.09869909286499)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 25, iter: 4, G-Loss:  (-3.4206008911132812, 25.420425415039062, -37.929439544677734, 9.088413715362549)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 26, iter: 0, G-Loss:  (-5.481184959411621, 23.68829345703125, -38.248897552490234, 9.079419374465942)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 26, iter: 1, G-Loss:  (-5.690422058105469, 24.01650047302246, -38.775146484375, 9.06822383403778)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 26, iter: 2, G-Loss:  (-5.906667709350586, 24.35475730895996, -39.3181266784668, 9.05670166015625)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 26, iter: 3, G-Loss:  (-6.126142501831055, 24.69781494140625, -39.86900329589844, 9.045045375823975)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 26, iter: 4, G-Loss:  (-6.347400665283203, 25.0441951751709, -40.42477798461914, 9.03318166732788)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 27, iter: 0, G-Loss:  (-6.872552871704102, 28.144222259521484, -44.03632736206055, 9.01955246925354)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 27, iter: 1, G-Loss:  (-7.100622177124023, 28.530397415161133, -44.638587951660156, 9.007568359375)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 27, iter: 2, G-Loss:  (-7.330575942993164, 28.917177200317383, -45.24337387084961, 8.995620608329773)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 27, iter: 3, G-Loss:  (-7.561738014221191, 29.30538558959961, -45.85060119628906, 8.98347795009613)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 27, iter: 4, G-Loss:  (-7.793571472167969, 29.695377349853516, -46.460330963134766, 8.971381783485413)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 28, iter: 0, G-Loss:  (-7.302212715148926, 29.138853073120117, -45.401817321777344, 8.960751295089722)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 28, iter: 1, G-Loss:  (-7.52316951751709, 29.515953063964844, -45.98793411254883, 8.948811292648315)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 28, iter: 2, G-Loss:  (-7.744291305541992, 29.892932891845703, -46.574222564697266, 8.93699824810028)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 28, iter: 3, G-Loss:  (-7.966510772705078, 30.271080017089844, -47.162391662597656, 8.924800753593445)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 28, iter: 4, G-Loss:  (-8.189336776733398, 30.650882720947266, -47.75321960449219, 8.912999629974365)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 29, iter: 0, G-Loss:  (-9.778700828552246, 35.67011260986328, -54.34939956665039, 8.900586366653442)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 29, iter: 1, G-Loss:  (-10.028266906738281, 36.12398147583008, -55.04027557373047, 8.888027667999268)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 29, iter: 2, G-Loss:  (-10.28294563293457, 36.58486557006836, -55.743072509765625, 8.875261545181274)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 29, iter: 3, G-Loss:  (-10.540130615234375, 37.04994201660156, -56.45243453979492, 8.862361907958984)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 29, iter: 4, G-Loss:  (-10.798760414123535, 37.517940521240234, -57.16608810424805, 8.849387168884277)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 30, iter: 0, G-Loss:  (-8.77479076385498, 28.583276748657227, -46.19369888305664, 8.835631012916565)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 30, iter: 1, G-Loss:  (-8.997456550598145, 28.928226470947266, -46.74874496459961, 8.82306158542633)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 30, iter: 2, G-Loss:  (-9.217947006225586, 29.268722534179688, -47.29733657836914, 8.810666799545288)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 30, iter: 3, G-Loss:  (-9.438427925109863, 29.608322143554688, -47.84500503540039, 8.79825472831726)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 30, iter: 4, G-Loss:  (-9.659978866577148, 29.948978424072266, -48.394775390625, 8.785818219184875)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 31, iter: 0, G-Loss:  (-12.2345552444458, 37.09394073486328, -58.102874755859375, 8.774378895759583)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 31, iter: 1, G-Loss:  (-12.49884033203125, 37.5373649597168, -58.79732131958008, 8.76111626625061)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 31, iter: 2, G-Loss:  (-12.771045684814453, 37.9913215637207, -59.50988006591797, 8.74751329421997)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 31, iter: 3, G-Loss:  (-13.047133445739746, 38.451087951660156, -60.23197937011719, 8.733757734298706)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 31, iter: 4, G-Loss:  (-13.32534122467041, 38.91460418701172, -60.95986557006836, 8.7199205160141)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 32, iter: 0, G-Loss:  (-11.614113807678223, 48.79610824584961, -69.11630249023438, 8.706080317497253)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 32, iter: 1, G-Loss:  (-11.861631393432617, 49.35424041748047, -69.90849304199219, 8.692620992660522)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 32, iter: 2, G-Loss:  (-12.10765266418457, 49.902793884277344, -70.68983459472656, 8.67938756942749)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 32, iter: 3, G-Loss:  (-12.353780746459961, 50.45018005371094, -71.47013854980469, 8.666177988052368)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 32, iter: 4, G-Loss:  (-12.60091495513916, 50.99955368041992, -72.25341033935547, 8.652941584587097)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 33, iter: 0, G-Loss:  (-15.615869522094727, 38.93437194824219, -63.190330505371094, 8.64008903503418)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 33, iter: 1, G-Loss:  (-15.909855842590332, 39.38480758666992, -63.92053985595703, 8.625876307487488)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 33, iter: 2, G-Loss:  (-16.212493896484375, 39.849849700927734, -64.67363739013672, 8.611292839050293)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 33, iter: 3, G-Loss:  (-16.519289016723633, 40.321571350097656, -65.43733978271484, 8.596479892730713)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 33, iter: 4, G-Loss:  (-16.828166961669922, 40.79731750488281, -66.20708465576172, 8.581598997116089)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 34, iter: 0, G-Loss:  (-13.275031089782715, 33.90593338012695, -55.74702453613281, 8.566060066223145)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 34, iter: 1, G-Loss:  (-13.52695369720459, 34.281532287597656, -56.3603401184082, 8.551854491233826)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 34, iter: 2, G-Loss:  (-13.77417278289795, 34.65046310424805, -56.96266174316406, 8.538026213645935)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 34, iter: 3, G-Loss:  (-14.0208101272583, 35.0181770324707, -57.56306076049805, 8.524073362350464)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 34, iter: 4, G-Loss:  (-14.268489837646484, 35.387428283691406, -58.16605758666992, 8.510138988494873)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 35, iter: 0, G-Loss:  (-23.98284149169922, 54.95514678955078, -87.43272399902344, 8.494735956192017)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 35, iter: 1, G-Loss:  (-24.38317108154297, 55.60768508911133, -88.46943664550781, 8.478580117225647)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 35, iter: 2, G-Loss:  (-24.805679321289062, 56.29330825805664, -89.56058502197266, 8.461597561836243)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 35, iter: 3, G-Loss:  (-25.23569107055664, 56.99100112915039, -90.67105865478516, 8.44436526298523)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 35, iter: 4, G-Loss:  (-25.666915893554688, 57.69047927856445, -91.78459930419922, 8.427205085754395)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 36, iter: 0, G-Loss:  (-25.818592071533203, 51.72502136230469, -85.9574203491211, 8.413807153701782)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 36, iter: 1, G-Loss:  (-26.243804931640625, 52.346561431884766, -86.9871597290039, 8.396793007850647)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 36, iter: 2, G-Loss:  (-26.668153762817383, 52.96685791015625, -88.01470184326172, 8.379690051078796)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 36, iter: 3, G-Loss:  (-27.090980529785156, 53.583744049072266, -89.0374984741211, 8.362773060798645)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 36, iter: 4, G-Loss:  (-27.512683868408203, 54.199127197265625, -90.05775451660156, 8.345942497253418)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 37, iter: 0, G-Loss:  (-19.31815528869629, 44.8139533996582, -72.45724487304688, 8.325135707855225)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 37, iter: 1, G-Loss:  (-19.61301040649414, 45.27174377441406, -73.19447326660156, 8.309717774391174)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 37, iter: 2, G-Loss:  (-19.89608383178711, 45.70951461791992, -73.90064239501953, 8.295043706893921)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 37, iter: 3, G-Loss:  (-20.175580978393555, 46.14191818237305, -74.59809875488281, 8.2805997133255)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 37, iter: 4, G-Loss:  (-20.455730438232422, 46.57526397705078, -75.29708862304688, 8.266093730926514)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 38, iter: 0, G-Loss:  (-20.04592514038086, 54.359676361083984, -82.65995788574219, 8.25435757637024)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 38, iter: 1, G-Loss:  (-20.322891235351562, 54.86461639404297, -83.4273910522461, 8.239882588386536)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 38, iter: 2, G-Loss:  (-20.603391647338867, 55.3746337890625, -84.20320129394531, 8.225175738334656)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 38, iter: 3, G-Loss:  (-20.88753890991211, 55.888282775878906, -84.98625183105469, 8.21043074131012)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 38, iter: 4, G-Loss:  (-21.175495147705078, 56.40875244140625, -85.77973937988281, 8.195491433143616)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 39, iter: 0, G-Loss:  (-16.81760597229004, 43.00060272216797, -67.99638366699219, 8.178174495697021)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 39, iter: 1, G-Loss:  (-17.05386734008789, 43.383968353271484, -68.60147857666016, 8.163644075393677)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 39, iter: 2, G-Loss:  (-17.287342071533203, 43.76212692260742, -69.1987533569336, 8.14928412437439)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 39, iter: 3, G-Loss:  (-17.521745681762695, 44.14189147949219, -69.79853057861328, 8.134893774986267)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 39, iter: 4, G-Loss:  (-17.758941650390625, 44.526588439941406, -70.40586853027344, 8.120339512825012)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 40, iter: 0, G-Loss:  (-24.313901901245117, 57.1949462890625, -89.61658477783203, 8.107736110687256)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 40, iter: 1, G-Loss:  (-24.640554428100586, 57.74563980102539, -90.47769927978516, 8.091504573822021)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 40, iter: 2, G-Loss:  (-24.983978271484375, 58.32312774658203, -91.38158416748047, 8.074477314949036)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 40, iter: 3, G-Loss:  (-25.336030960083008, 58.91347122192383, -92.30656433105469, 8.057062029838562)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 40, iter: 4, G-Loss:  (-25.692813873291016, 59.51262283325195, -93.2448959350586, 8.039458990097046)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 41, iter: 0, G-Loss:  (-21.363075256347656, 54.26777267456055, -83.65332794189453, 8.02247941493988)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 41, iter: 1, G-Loss:  (-21.66205596923828, 54.791866302490234, -84.45951080322266, 8.005589842796326)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 41, iter: 2, G-Loss:  (-21.956619262695312, 55.30826187133789, -85.25386810302734, 7.988985776901245)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 41, iter: 3, G-Loss:  (-22.25070571899414, 55.82285690307617, -86.04605865478516, 7.972496747970581)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 41, iter: 4, G-Loss:  (-22.546384811401367, 56.34000015258789, -86.84226989746094, 7.955884337425232)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 42, iter: 0, G-Loss:  (-27.838790893554688, 59.3054313659668, -95.08460998535156, 7.940388917922974)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 42, iter: 1, G-Loss:  (-28.206069946289062, 59.88882827758789, -96.01737976074219, 7.922482490539551)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 42, iter: 2, G-Loss:  (-28.585872650146484, 60.49055099487305, -96.9804458618164, 7.904021143913269)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 42, iter: 3, G-Loss:  (-28.971752166748047, 61.10068893432617, -97.95780944824219, 7.885369062423706)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 42, iter: 4, G-Loss:  (-29.36089324951172, 61.716758728027344, -98.9442138671875, 7.866562008857727)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 43, iter: 0, G-Loss:  (-22.665603637695312, 56.48441696166992, -86.99665069580078, 7.846630215644836)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 43, iter: 1, G-Loss:  (-22.964664459228516, 57.00632858276367, -87.80003356933594, 7.829041481018066)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 43, iter: 2, G-Loss:  (-23.255651473999023, 57.5128059387207, -88.58045196533203, 7.811994552612305)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 43, iter: 3, G-Loss:  (-23.544639587402344, 58.01534652709961, -89.35517883300781, 7.79519259929657)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 43, iter: 4, G-Loss:  (-23.834989547729492, 58.51866912841797, -90.13178253173828, 7.778124213218689)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 44, iter: 0, G-Loss:  (-26.30232810974121, 81.2181625366211, -115.27558135986328, 7.755090594291687)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 44, iter: 1, G-Loss:  (-26.625328063964844, 81.93576049804688, -116.298583984375, 7.737494707107544)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 44, iter: 2, G-Loss:  (-26.956148147583008, 82.66560363769531, -117.34136962890625, 7.719617486000061)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 44, iter: 3, G-Loss:  (-27.291912078857422, 83.40528106689453, -118.39871215820312, 7.701519727706909)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 44, iter: 4, G-Loss:  (-27.631338119506836, 84.15416717529297, -119.46868133544922, 7.683175802230835)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 45, iter: 0, G-Loss:  (-30.831850051879883, 73.12325286865234, -111.62101745605469, 7.665914297103882)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 45, iter: 1, G-Loss:  (-31.214744567871094, 73.81304931640625, -112.67439270019531, 7.646598815917969)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 45, iter: 2, G-Loss:  (-31.606094360351562, 74.52045440673828, -113.75344848632812, 7.626898884773254)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 45, iter: 3, G-Loss:  (-32.00184631347656, 75.23851776123047, -114.84735107421875, 7.606987357139587)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 45, iter: 4, G-Loss:  (-32.400177001953125, 75.96045684814453, -115.94759368896484, 7.586957812309265)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 46, iter: 0, G-Loss:  (-34.9312629699707, 74.1067123413086, -116.60802459716797, 7.570047974586487)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 46, iter: 1, G-Loss:  (-35.361026763916016, 74.82833862304688, -117.73900604248047, 7.549639940261841)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 46, iter: 2, G-Loss:  (-35.79620361328125, 75.55633544921875, -118.88155364990234, 7.529014348983765)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 46, iter: 3, G-Loss:  (-36.23380661010742, 76.28617858886719, -120.0282974243164, 7.5083136558532715)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 46, iter: 4, G-Loss:  (-36.672691345214844, 77.02005767822266, -121.18041229248047, 7.48766303062439)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 47, iter: 0, G-Loss:  (-39.389373779296875, 79.58097839355469, -126.44173431396484, 7.471383810043335)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 47, iter: 1, G-Loss:  (-39.8613395690918, 80.35370635986328, -127.66532135009766, 7.450276613235474)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 47, iter: 2, G-Loss:  (-40.33857727050781, 81.13192749023438, -128.89947509765625, 7.428972125053406)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 47, iter: 3, G-Loss:  (-40.817832946777344, 81.91181945800781, -130.13735961914062, 7.407705187797546)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 47, iter: 4, G-Loss:  (-41.29798126220703, 82.69408416748047, -131.3785400390625, 7.386475205421448)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 48, iter: 0, G-Loss:  (-30.18507957458496, 86.6681137084961, -124.21227264404297, 7.359079718589783)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 48, iter: 1, G-Loss:  (-30.524507522583008, 87.4056625366211, -125.26984405517578, 7.339674234390259)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 48, iter: 2, G-Loss:  (-30.85072135925293, 88.11155700683594, -126.28351593017578, 7.321237325668335)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 48, iter: 3, G-Loss:  (-31.173072814941406, 88.80789947509766, -127.28399658203125, 7.303024530410767)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 48, iter: 4, G-Loss:  (-31.496070861816406, 89.50447082519531, -128.28543090820312, 7.284889221191406)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 49, iter: 0, G-Loss:  (-34.488468170166016, 73.96210479736328, -115.7267074584961, 7.276135087013245)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 49, iter: 1, G-Loss:  (-34.8477668762207, 74.56480407714844, -116.66981506347656, 7.257243394851685)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 49, iter: 2, G-Loss:  (-35.2163200378418, 75.18389892578125, -117.63813781738281, 7.23791778087616)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 49, iter: 3, G-Loss:  (-35.59136199951172, 75.81402587890625, -118.6236572265625, 7.218267321586609)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 49, iter: 4, G-Loss:  (-35.971473693847656, 76.45439147949219, -119.62419891357422, 7.198335528373718)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 50, iter: 0, G-Loss:  (-39.45048904418945, 94.01912689208984, -140.64273071289062, 7.173116207122803)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 50, iter: 1, G-Loss:  (-39.87586975097656, 94.83432006835938, -141.8626251220703, 7.152436375617981)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 50, iter: 2, G-Loss:  (-40.31023406982422, 95.66229248046875, -143.10386657714844, 7.1313393115997314)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 50, iter: 3, G-Loss:  (-40.749515533447266, 96.5001449584961, -144.35980224609375, 7.110140323638916)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 50, iter: 4, G-Loss:  (-41.19206619262695, 97.34425354003906, -145.6251220703125, 7.088803648948669)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 51, iter: 0, G-Loss:  (-42.67551040649414, 90.34324645996094, -140.0917510986328, 7.072992920875549)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 51, iter: 1, G-Loss:  (-43.13530349731445, 91.14093017578125, -141.3275604248047, 7.05132782459259)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 51, iter: 2, G-Loss:  (-43.59939193725586, 91.9457015991211, -142.57461547851562, 7.029523253440857)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 51, iter: 3, G-Loss:  (-44.066287994384766, 92.75718688964844, -143.83106994628906, 7.0075953006744385)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 51, iter: 4, G-Loss:  (-44.535194396972656, 93.5712890625, -145.09214782714844, 6.985665559768677)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 52, iter: 0, G-Loss:  (-38.18129348754883, 89.19123840332031, -134.32470703125, 6.95217490196228)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 52, iter: 1, G-Loss:  (-38.57400894165039, 89.92874145507812, -135.43394470214844, 6.931192874908447)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 52, iter: 2, G-Loss:  (-38.960384368896484, 90.65111541748047, -136.5220947265625, 6.91059410572052)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 52, iter: 3, G-Loss:  (-39.34584045410156, 91.37061309814453, -137.6065673828125, 6.8901121616363525)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 52, iter: 4, G-Loss:  (-39.73319625854492, 92.09541320800781, -138.6982421875, 6.869632601737976)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 53, iter: 0, G-Loss:  (-49.36489486694336, 94.98411560058594, -151.20681762695312, 6.857805848121643)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 53, iter: 1, G-Loss:  (-49.86635208129883, 95.79682159423828, -152.4989471435547, 6.835773587226868)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 53, iter: 2, G-Loss:  (-50.38631057739258, 96.63811492919922, -153.83738708496094, 6.812962889671326)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 53, iter: 3, G-Loss:  (-50.91459274291992, 97.4906234741211, -155.19508361816406, 6.789867877960205)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 53, iter: 4, G-Loss:  (-51.44667053222656, 98.35015869140625, -156.5634765625, 6.766648888587952)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 54, iter: 0, G-Loss:  (-42.36375427246094, 85.76129150390625, -134.8616943359375, 6.736648082733154)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 54, iter: 1, G-Loss:  (-42.78715896606445, 86.47058868408203, -135.9724578857422, 6.714710593223572)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 54, iter: 2, G-Loss:  (-43.20018005371094, 87.16377258300781, -137.0573272705078, 6.693373918533325)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 54, iter: 3, G-Loss:  (-43.61061096191406, 87.85123443603516, -138.13400268554688, 6.672155261039734)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 54, iter: 4, G-Loss:  (-44.02204132080078, 88.54049682617188, -139.21359252929688, 6.651052236557007)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 55, iter: 0, G-Loss:  (-59.583213806152344, 131.16453552246094, -197.37615966796875, 6.6284096240997314)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 55, iter: 1, G-Loss:  (-60.176509857177734, 132.29205322265625, -199.07357788085938, 6.605014204978943)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 55, iter: 2, G-Loss:  (-60.79728698730469, 133.46444702148438, -200.84225463867188, 6.580522656440735)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 55, iter: 3, G-Loss:  (-61.42856979370117, 134.6553192138672, -202.63954162597656, 6.555651426315308)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 55, iter: 4, G-Loss:  (-62.0627326965332, 135.85235595703125, -204.4459991455078, 6.530911326408386)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 56, iter: 0, G-Loss:  (-48.219154357910156, 116.15502166748047, -170.87425231933594, 6.500076651573181)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 56, iter: 1, G-Loss:  (-48.685279846191406, 117.09416961669922, -172.25607299804688, 6.476624011993408)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 56, iter: 2, G-Loss:  (-49.13311004638672, 118.00015258789062, -173.58877563476562, 6.45551323890686)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 56, iter: 3, G-Loss:  (-49.575927734375, 118.89399719238281, -174.90399169921875, 6.43406867980957)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 56, iter: 4, G-Loss:  (-50.01875686645508, 119.78744506835938, -176.2188262939453, 6.412625312805176)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 57, iter: 0, G-Loss:  (-58.83778762817383, 115.88028717041016, -181.12820434570312, 6.410129070281982)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 57, iter: 1, G-Loss:  (-59.37825393676758, 116.80205535888672, -182.56785583496094, 6.387547850608826)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 57, iter: 2, G-Loss:  (-59.93585205078125, 117.75181579589844, -184.05198669433594, 6.364317536354065)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 57, iter: 3, G-Loss:  (-60.502281188964844, 118.71723937988281, -185.56011962890625, 6.340600252151489)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 57, iter: 4, G-Loss:  (-61.073081970214844, 119.69214630126953, -187.08241271972656, 6.317183971405029)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 58, iter: 0, G-Loss:  (-51.02632522583008, 147.03634643554688, -204.3351287841797, 6.272457242012024)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 58, iter: 1, G-Loss:  (-51.48740005493164, 148.15586853027344, -205.8933868408203, 6.250118017196655)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 58, iter: 2, G-Loss:  (-51.938804626464844, 149.2457275390625, -207.4128875732422, 6.228353381156921)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 58, iter: 3, G-Loss:  (-52.38793182373047, 150.32882690429688, -208.92364501953125, 6.206885576248169)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 58, iter: 4, G-Loss:  (-52.83880615234375, 151.41481018066406, -210.43902587890625, 6.185410022735596)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 59, iter: 0, G-Loss:  (-62.91899871826172, 148.48202514648438, -217.56668090820312, 6.1656564474105835)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 59, iter: 1, G-Loss:  (-63.480438232421875, 149.63197326660156, -219.25502014160156, 6.142610311508179)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 59, iter: 2, G-Loss:  (-64.06138610839844, 150.8222198486328, -221.00233459472656, 6.1187320947647095)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 59, iter: 3, G-Loss:  (-64.65203857421875, 152.03431701660156, -222.7806854248047, 6.09432578086853)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 59, iter: 4, G-Loss:  (-65.24729919433594, 153.25672912597656, -224.5741424560547, 6.070117354393005)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 60, iter: 0, G-Loss:  (-66.03791809082031, 104.07621002197266, -176.18582153320312, 6.071692705154419)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 60, iter: 1, G-Loss:  (-66.63876342773438, 104.91339111328125, -177.5997772216797, 6.047626733779907)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 60, iter: 2, G-Loss:  (-67.24217987060547, 105.75499725341797, -179.02073669433594, 6.023557186126709)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 60, iter: 3, G-Loss:  (-67.84911346435547, 106.59980010986328, -180.4467315673828, 5.997815728187561)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 60, iter: 4, G-Loss:  (-68.4540786743164, 107.44538116455078, -181.87513732910156, 5.975679159164429)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 61, iter: 0, G-Loss:  (-85.90831756591797, 147.90740966796875, -239.75979614257812, 5.944066643714905)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 61, iter: 1, G-Loss:  (-86.71000671386719, 149.16397094726562, -241.7920684814453, 5.918094515800476)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 61, iter: 2, G-Loss:  (-87.53628540039062, 150.45762634277344, -243.88510131835938, 5.891191363334656)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 61, iter: 3, G-Loss:  (-88.368896484375, 151.7616424560547, -245.99530029296875, 5.864763259887695)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 61, iter: 4, G-Loss:  (-89.20109558105469, 153.06370544433594, -248.1031951904297, 5.8383965492248535)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 62, iter: 0, G-Loss:  (-77.33991241455078, 177.41746520996094, -260.553466796875, 5.796087384223938)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 62, iter: 1, G-Loss:  (-78.02433776855469, 178.82229614257812, -262.6179504394531, 5.771313905715942)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 62, iter: 2, G-Loss:  (-78.69261932373047, 180.18809509277344, -264.628173828125, 5.747462511062622)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 62, iter: 3, G-Loss:  (-79.35455322265625, 181.53753662109375, -266.6160583496094, 5.723966360092163)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 62, iter: 4, G-Loss:  (-80.01561737060547, 182.88259887695312, -268.5984802246094, 5.7002633810043335)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 63, iter: 0, G-Loss:  (-64.28729248046875, 154.18035888671875, -224.14486694335938, 5.677218437194824)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 63, iter: 1, G-Loss:  (-64.78947448730469, 155.22897338867188, -225.6741943359375, 5.655743479728699)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 63, iter: 2, G-Loss:  (-65.27745819091797, 156.2466583251953, -227.15904235839844, 5.634923577308655)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 63, iter: 3, G-Loss:  (-65.76258087158203, 157.25588989257812, -228.6326446533203, 5.614176392555237)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 63, iter: 4, G-Loss:  (-66.2499771118164, 158.2703399658203, -230.11398315429688, 5.593666434288025)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 64, iter: 0, G-Loss:  (-77.65665435791016, 135.64903259277344, -218.88926696777344, 5.583580136299133)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 64, iter: 1, G-Loss:  (-78.26121520996094, 136.6017608642578, -220.4236602783203, 5.560682415962219)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 64, iter: 2, G-Loss:  (-78.88710021972656, 137.5953826904297, -222.0209503173828, 5.538464188575745)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 64, iter: 3, G-Loss:  (-79.5263900756836, 138.60824584960938, -223.64974975585938, 5.515116453170776)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 64, iter: 4, G-Loss:  (-80.17354583740234, 139.63406372070312, -225.2991943359375, 5.491588115692139)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 65, iter: 0, G-Loss:  (-83.4577407836914, 178.05308532714844, -266.9660339355469, 5.4552072286605835)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 65, iter: 1, G-Loss:  (-84.1433334350586, 179.38014221191406, -268.9542236328125, 5.430745482444763)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 65, iter: 2, G-Loss:  (-84.83580017089844, 180.7181396484375, -270.9609069824219, 5.406968593597412)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 65, iter: 3, G-Loss:  (-85.53316497802734, 182.06349182128906, -272.9794006347656, 5.382745862007141)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 65, iter: 4, G-Loss:  (-86.23451232910156, 183.4137725830078, -275.0059814453125, 5.357698202133179)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 66, iter: 0, G-Loss:  (-80.28348541259766, 141.39671325683594, -227.03355407714844, 5.3533583879470825)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 66, iter: 1, G-Loss:  (-80.92138671875, 142.41798400878906, -228.6695098876953, 5.330138802528381)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 66, iter: 2, G-Loss:  (-81.55470275878906, 143.43429565429688, -230.29640197753906, 5.307402610778809)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 66, iter: 3, G-Loss:  (-82.18844604492188, 144.44970703125, -231.92279052734375, 5.284633636474609)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 66, iter: 4, G-Loss:  (-82.82463073730469, 145.4691925048828, -233.55592346191406, 5.2621012926101685)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 67, iter: 0, G-Loss:  (-91.51577758789062, 162.42588806152344, -259.1777038574219, 5.236039161682129)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 67, iter: 1, G-Loss:  (-92.24070739746094, 163.6102294921875, -261.0634765625, 5.212541222572327)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 67, iter: 2, G-Loss:  (-92.98077392578125, 164.81712341308594, -262.98638916015625, 5.188493728637695)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 67, iter: 3, G-Loss:  (-93.72820281982422, 166.03543090820312, -264.9283142089844, 5.164681077003479)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 67, iter: 4, G-Loss:  (-94.47982025146484, 167.26051330566406, -266.88116455078125, 5.140830874443054)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 68, iter: 0, G-Loss:  (-87.52071380615234, 179.73666381835938, -272.3635559082031, 5.106174945831299)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 68, iter: 1, G-Loss:  (-88.20094299316406, 181.008544921875, -274.292236328125, 5.082744359970093)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 68, iter: 2, G-Loss:  (-88.8744125366211, 182.26588439941406, -276.20086669921875, 5.060572028160095)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 68, iter: 3, G-Loss:  (-89.54814910888672, 183.52517700195312, -278.1112060546875, 5.037880539894104)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 68, iter: 4, G-Loss:  (-90.22378540039062, 184.78594970703125, -280.0252990722656, 5.015566349029541)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 69, iter: 0, G-Loss:  (-98.94577026367188, 172.1414031982422, -276.0693664550781, 4.9821969866752625)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 69, iter: 1, G-Loss:  (-99.708984375, 173.36956787109375, -278.0375061035156, 4.958954751491547)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 69, iter: 2, G-Loss:  (-100.48722076416016, 174.62396240234375, -280.04644775390625, 4.9352627992630005)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 69, iter: 3, G-Loss:  (-101.27307891845703, 175.89215087890625, -282.07672119140625, 4.911492466926575)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 69, iter: 4, G-Loss:  (-102.06310272216797, 177.1667022705078, -284.11761474609375, 4.887807071208954)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 70, iter: 0, G-Loss:  (-105.75652313232422, 239.7142333984375, -350.3374938964844, 4.866740703582764)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 70, iter: 1, G-Loss:  (-106.57902526855469, 241.43788146972656, -352.8603515625, 4.843446612358093)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 70, iter: 2, G-Loss:  (-107.40769958496094, 243.16624450683594, -355.39422607421875, 4.8202845454216)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 70, iter: 3, G-Loss:  (-108.23930358886719, 244.89431762695312, -357.9307861328125, 4.7971609234809875)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 70, iter: 4, G-Loss:  (-109.07211303710938, 246.62664794921875, -360.47320556640625, 4.774448275566101)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 71, iter: 0, G-Loss:  (-109.00514221191406, 191.66390991210938, -305.43975830078125, 4.7707051038742065)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 71, iter: 1, G-Loss:  (-109.83087921142578, 193.01686096191406, -307.59619140625, 4.748452305793762)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 71, iter: 2, G-Loss:  (-110.6589126586914, 194.37521362304688, -309.760009765625, 4.725885093212128)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 71, iter: 3, G-Loss:  (-111.48878479003906, 195.74147033691406, -311.9336853027344, 4.70343291759491)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 71, iter: 4, G-Loss:  (-112.32041931152344, 197.10897827148438, -314.1108703613281, 4.68147486448288)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 72, iter: 0, G-Loss:  (-123.69915008544922, 248.7445526123047, -377.08740234375, 4.643696546554565)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 72, iter: 1, G-Loss:  (-124.64007568359375, 250.5258026123047, -379.78692626953125, 4.621049165725708)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 72, iter: 2, G-Loss:  (-125.59677124023438, 252.3331756591797, -382.52789306640625, 4.597947299480438)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 72, iter: 3, G-Loss:  (-126.56153106689453, 254.14991760253906, -385.2843322753906, 4.572885036468506)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 72, iter: 4, G-Loss:  (-127.52421569824219, 255.96987915039062, -388.0462951660156, 4.552204012870789)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 73, iter: 0, G-Loss:  (-123.99314880371094, 207.53573608398438, -336.08856201171875, 4.559678435325623)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 73, iter: 1, G-Loss:  (-124.91453552246094, 208.9975128173828, -338.4505920410156, 4.538546204566956)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ac18dfe4a3a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# # valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ff0558343830>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainloader, validloader)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;31m# train discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0miter_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoised_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     print(\"\\tVGG_MSE - lr: %.10f, Level: %d, Epoch: %d, bath_index: %d, iter: %d, G-Loss: \" %\n\u001b[1;32m     67\u001b[0m                           (self.lr, self.level, epoch, batch_index, iter_i), loss)\n",
            "\u001b[0;32m<ipython-input-16-ff0558343830>\u001b[0m in \u001b[0;36m_train_discriminator\u001b[0;34m(self, clean_img, noised_img, train)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreal_validity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_validity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_gp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;31m# torch.mean(-real_validity).backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# (torch.mean(-real_validity) + torch.mean(fake_validity)).backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAHR059AR3G9",
        "outputId": "b05cac30-9506-4a7a-bbc1-727ac8fc845a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "# Clear GPU memory\n",
        "wgan = None\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "1/0;"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6abec2edcb8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1mdT2ETROFv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}