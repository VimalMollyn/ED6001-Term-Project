{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Training dev nb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e3a19c2b8ef4987b03e1707fc2c543f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e6bbc3cff364dd59cefa6d7a92b164a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ce78a3651bf4c97b32988cce9332254",
              "IPY_MODEL_4f6a00c5a9e04cbd9b60f9e837ed0290",
              "IPY_MODEL_b9026923673b4e1d9d8ed11a449b4a95"
            ]
          }
        },
        "3e6bbc3cff364dd59cefa6d7a92b164a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ce78a3651bf4c97b32988cce9332254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53ac1e81fabd4c71b65571bc0da092d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1eaa39742bd945cf9c87e70e06619d0d"
          }
        },
        "4f6a00c5a9e04cbd9b60f9e837ed0290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76125ec17d7a456fa576010fcd2dcab2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_237976c10cb64e01b01fae8e7aededa3"
          }
        },
        "b9026923673b4e1d9d8ed11a449b4a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd20104fc7374f8b95c098fdba26bc39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [04:20&lt;00:00,  2.69s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3ca1ffe201941b38fcd9831daa83f62"
          }
        },
        "53ac1e81fabd4c71b65571bc0da092d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1eaa39742bd945cf9c87e70e06619d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76125ec17d7a456fa576010fcd2dcab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "237976c10cb64e01b01fae8e7aededa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd20104fc7374f8b95c098fdba26bc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3ca1ffe201941b38fcd9831daa83f62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdcd5afb38b64c8a8891a71a8eee8ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64f5d443eed543f993fd7eaac3395138",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec6394f021864bbbb9f21a952b9a0606",
              "IPY_MODEL_dbca70dd8d964370b0afc180ce6ad22a",
              "IPY_MODEL_a6014b56010a46ec9d2d0fc679c52108"
            ]
          }
        },
        "64f5d443eed543f993fd7eaac3395138": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec6394f021864bbbb9f21a952b9a0606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50252f999daf42ba8c5e4bd8e4f87a9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f72bf69c85641589f8528d2b495fabe"
          }
        },
        "dbca70dd8d964370b0afc180ce6ad22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbc1ee1fa9e14234abcf41098640a061",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32abd0040074a21abe775b76d899df4"
          }
        },
        "a6014b56010a46ec9d2d0fc679c52108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0310da08f870404dbc14b5f5232ec402",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [00:26&lt;00:00,  2.75s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee3d42708d804aafa65343d55dc98d1d"
          }
        },
        "50252f999daf42ba8c5e4bd8e4f87a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f72bf69c85641589f8528d2b495fabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbc1ee1fa9e14234abcf41098640a061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32abd0040074a21abe775b76d899df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0310da08f870404dbc14b5f5232ec402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee3d42708d804aafa65343d55dc98d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VimalMollyn/ED6001-Term-Project/blob/colab/Training/Notebooks/2.%20Training%20dev%20nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv1VVaDjK1ec",
        "outputId": "2c2a3f25-6e1e-4418-852e-b7d937127049"
      },
      "source": [
        "## stuff to include at the start of each notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone -b colab https://github.com/VimalMollyn/ED6001-Term-Project.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'ED6001-Term-Project'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 135 (delta 60), reused 52 (delta 15), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (135/135), 9.68 MiB | 22.99 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ausM4SOo-kck"
      },
      "source": [
        "# !rm -r /content/ED6001-Term-Project/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KfRJ8JOMDOh",
        "outputId": "0a246e8e-eba6-4b34-9964-25ed85e1b4fe"
      },
      "source": [
        "!conda install scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs9QqrGmL7vP"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'ED6001-Term-Project/Training/')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hov55xbhLfyY"
      },
      "source": [
        "## imports go here\n",
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity, normalized_root_mse\n",
        "\n",
        "from preprocessing import patch_test_img, merge_test_img\n",
        "# from data import MRIDataset ## imports for the MRI dataset\n",
        "from pathlib import Path\n",
        "\n",
        "'''\n",
        "Version: 0.0.1\n",
        "Date: 2018-04-01\n",
        "Structure:\n",
        "    Generator: Residual connection\n",
        "        input  -> 32 -> 64 -> 128 -> 256 \n",
        "        output <- 32 <- 64 <- 128 <——\n",
        "\n",
        "        encoder layer: Conv3d -> BatchNorm3d -> LeakyReLu\n",
        "        decoder layer: Conv3D - > Add encoder -> BatchNorm3d -> LeakyReLU(expect last layer is ReLu)\n",
        "    Disciminator:\n",
        "        input -> 32 -> 64 -> 128 -> 1\n",
        "        Except last layer:Conv3d -> BatchNorm3d -> LeakyReLu\n",
        "        Last layer: Full Connection(no active function)\n",
        "'''\n",
        "\n",
        "\n",
        "class GeneratorNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv3d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        # torch.nn.init.\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm3d(256),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.deConv1_1 = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n",
        "        self.deConv1 = nn.Sequential(\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.deConv2_1 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n",
        "        self.deConv2 = nn.Sequential(\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.deConv3_1 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n",
        "        self.deConv3 = nn.Sequential(\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.deConv4_1 = nn.Conv3d(32, 1, kernel_size=3, padding=1)\n",
        "\n",
        "        self.deConv4 = nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        conv1 = self.conv1(input)\n",
        "\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "        conv4 = self.conv4(conv3)\n",
        "\n",
        "        x = self.deConv1_1(conv4)\n",
        "        x = x + conv3\n",
        "\n",
        "        deConv1 = self.deConv1(x)\n",
        "\n",
        "        x = self.deConv2_1(deConv1)\n",
        "        x += conv2\n",
        "        deConv2 = self.deConv2(x)\n",
        "\n",
        "        x = self.deConv3_1(deConv2)\n",
        "        x += conv1\n",
        "        deConv3 = self.deConv3(x)\n",
        "\n",
        "        x = self.deConv4_1(deConv3)\n",
        "        x += input\n",
        "        output = self.deConv4(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class DiscriminatorNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv3d(1, 32, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm3d(32),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm3d(64),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm3d(128),\n",
        "            nn.LeakyReLU()\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(128 * 6 * 32 * 32, 1)\n",
        "        # self.fc2 = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        output = self.fc(x)\n",
        "        # output = self.fc2(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for i in size:\n",
        "            num_features *= i\n",
        "\n",
        "        return num_features\n",
        "\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG19, self).__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True)\n",
        "        self.feature = vgg19.features\n",
        "    '''\n",
        "    input: N*1*D(6)*H*W\n",
        "    output: N*C*H*W\n",
        "    '''\n",
        "\n",
        "    def forward(self, input):\n",
        "        # VGG19: means:103.939, 116.779, 123.68\n",
        "        input /= 16\n",
        "        depth = input.size()[2]\n",
        "        result = []\n",
        "        for i in range(depth):\n",
        "            x = torch.cat(\n",
        "                (input[:, :, i, :, :] - 103.939, input[:, :, i, :, :] - 116.779, input[:, :, i, :, :] - 123.68), 1)\n",
        "            result.append(self.feature(x))\n",
        "\n",
        "        output = torch.cat(result, dim=1)\n",
        "\n",
        "        # output = self.feature(input)\n",
        "\n",
        "        return output\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohdln8DRMoJW"
      },
      "source": [
        "def initialize_weights(*models):\n",
        "    for model in models:\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Conv3d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm3d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8BYcjNmOLO_"
      },
      "source": [
        "class WGAN():\n",
        "    def __init__(self, path_to_data, level=0):\n",
        "        # parameters\n",
        "        self.epochs = 10\n",
        "        # self.batch_size = 120\n",
        "        self.batch_size = 110\n",
        "        self.lr =5e-6\n",
        "        #  self.lr = 0.0000125000\n",
        "\n",
        "        self.d_iter = 5\n",
        "        self.lambda_gp = 10\n",
        "        # self.lambda_vgg = 1e-3\n",
        "        # self.lambda_d = 1e-5\n",
        "\n",
        "        self.lambda_vgg = 1e-1\n",
        "        self.lambda_d = 1e-3\n",
        "        self.lambda_mse = 1\n",
        "\n",
        "        self.level = level\n",
        "\n",
        "        self.loss_dir = \"./loss/\"\n",
        "        # self.v = \"0_0_1_15\" # ter\n",
        "        self.v = \"0_0_5_%d\" % self.level  # vs\n",
        "        self.save_dir = \"./model/\" + self.v + \"/\"\n",
        "        Path(self.loss_dir).mkdir(parents=True, exist_ok=True)\n",
        "        Path(self.save_dir).mkdir(parents=True, exist_ok=True)\n",
        "        self.gpu = False\n",
        "\n",
        "        self.generator = GeneratorNet()\n",
        "        self.discriminator = DiscriminatorNet()\n",
        "        self.vgg19 = VGG19()\n",
        "\n",
        "        self.G_optimizer = optim.Adam(\n",
        "            self.generator.parameters(), lr=self.lr, betas=(0.5, 0.9))\n",
        "        self.D_optimizer = optim.Adam(\n",
        "            self.discriminator.parameters(), lr=self.lr, betas=(0.5, 0.9))\n",
        "\n",
        "        # self.G_optimizer = optim.RMSprop(self.generator.parameters())\n",
        "        # self.D_optimizer = optim.RMSprop(self.discriminator.parameters())\n",
        "\n",
        "        self.G_loss = nn.MSELoss()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.generator.cuda()\n",
        "            self.discriminator.cuda()\n",
        "            self.vgg19.cuda()\n",
        "            self.gpu = True\n",
        "        if not self.load_model():\n",
        "            initialize_weights(self.generator)\n",
        "            initialize_weights(self.discriminator)\n",
        "\n",
        "    def train(self):\n",
        "        self.dataset = MRIDataset(path_to_data=path_to_data, split=\"train\")\n",
        "        # self.dataset = MRIDataset10125()\n",
        "        self.dataloader = DataLoader(\n",
        "            self.dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        self.validDataset = MRIDataset(path_to_data=path_to_data, split=\"test\")\n",
        "        self.validDataloader = DataLoader(\n",
        "            self.validDataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "        ## training loop\n",
        "        for epoch in range(0, self.epochs):\n",
        "            self.test(epoch)\n",
        "            # iterate over the dataset\n",
        "            for batch_index, batch in enumerate(self.dataloader):\n",
        "                # if (batch_index % 100 == 0):\n",
        "                #     self.test(epoch)\n",
        "                # print(\"epoch:\", epoch, \";batch number:\", batch_index, \";D_Loss:\", end=\"\")\n",
        "                clean_img = batch[\"clean_img\"]\n",
        "                noised_img = batch[\"noisy_img\"]\n",
        "                # print(type(noised_img))\n",
        "\n",
        "                # train discriminator\n",
        "                for iter_i in range(self.d_iter):\n",
        "                    loss = self._train_discriminator(clean_img, noised_img)\n",
        "                    print(\"\\tVGG_MSE - lr: %.10f, Level: %d, Epoch: %d, bath_index: %d, iter: %d, G-Loss: \" %\n",
        "                          (self.lr, self.level, epoch, batch_index, iter_i), loss)\n",
        "\n",
        "                # train generator\n",
        "                loss = self._train_generator(clean_img, noised_img)\n",
        "                # print(\"G Loss:%.4f, %.4f\" %\n",
        "                #    (float(loss[0]), float(loss[1])))\n",
        "\n",
        "                # save model and loss\n",
        "                if batch_index % 100 == 0:\n",
        "                    self.save_model()\n",
        "\n",
        "\n",
        "            if ((epoch + 1) % 4 == 0 and self.lr > 1e-7):\n",
        "                self.G_optimizer.defaults[\"lr\"] *= 0.5\n",
        "                self.G_optimizer.defaults[\"lr\"] *= 0.5\n",
        "                self.lr *= 0.5\n",
        "\n",
        "    def _train_discriminator(self, clean_img, noised_img, train=True):\n",
        "        self.D_optimizer.zero_grad()\n",
        "\n",
        "        z = Variable(noised_img)\n",
        "        real_img = Variable(clean_img / 4096)\n",
        "        if self.gpu:\n",
        "            z = z.cuda()\n",
        "            real_img = real_img.cuda()\n",
        "\n",
        "        fake_img = self.generator(z)\n",
        "        real_validity = self.discriminator(real_img)\n",
        "        fake_validity = self.discriminator(fake_img.data / 4096)\n",
        "        gradient_penalty = self._calc_gradient_penalty(\n",
        "            real_img.data, fake_img.data)\n",
        "\n",
        "        d_loss = torch.mean(-real_validity) + torch.mean(fake_validity) + \\\n",
        "            self.lambda_gp * gradient_penalty\n",
        "        if train:\n",
        "            d_loss.backward()\n",
        "            # torch.mean(-real_validity).backward()\n",
        "            # (torch.mean(-real_validity) + torch.mean(fake_validity)).backward()\n",
        "            # torch.mean(-real_validity).backward()\n",
        "            # torch.mean(fake_validity).backward()\n",
        "            self.D_optimizer.step()\n",
        "\n",
        "        return d_loss.data.item(), torch.mean(-real_validity).cpu().item(), torch.mean(fake_validity).cpu().item(), self.lambda_gp * gradient_penalty.cpu().item()\n",
        "\n",
        "    def _train_generator(self, clean_img, noised_img, train=True):\n",
        "        z = Variable(noised_img)\n",
        "        real_img = Variable(clean_img, requires_grad=False)\n",
        "\n",
        "\n",
        "        if self.gpu:\n",
        "            z = z.cuda()\n",
        "            real_img = real_img.cuda()\n",
        "\n",
        "        self.G_optimizer.zero_grad()\n",
        "        self.D_optimizer.zero_grad()\n",
        "        self.vgg19.zero_grad()\n",
        "\n",
        "        criterion_mse = nn.MSELoss()\n",
        "        criterion_vgg= nn.MSELoss()\n",
        "\n",
        "        fake_img = self.generator(z)\n",
        "        mse_loss = criterion_mse(fake_img, real_img)\n",
        "        if train:\n",
        "            (self.lambda_mse * mse_loss).backward(retain_graph=True)\n",
        "\n",
        "\n",
        "        feature_fake_vgg = self.vgg19(fake_img)\n",
        "        feature_real_vgg = Variable(self.vgg19(real_img).data, requires_grad=False).cuda()\n",
        "\n",
        "        vgg_loss = criterion_vgg(feature_fake_vgg, feature_real_vgg)\n",
        "\n",
        "        fake_validity = self.discriminator(fake_img / 4096)\n",
        "        # g_loss = self.lambda_mse * mse_loss + self.lambda_vgg * vgg_loss + self.lambda_d * torch.mean(-fake_validity)\n",
        "        g_loss =  self.lambda_vgg * vgg_loss + self.lambda_d * torch.mean(-fake_validity)\n",
        "\n",
        "        if train:\n",
        "            # (self.lambda_mse * mse_loss).backward()\n",
        "            g_loss.backward()\n",
        "            self.G_optimizer.step()\n",
        "        return g_loss.data.item(), mse_loss.data.item(), torch.mean(-fake_validity).data.item(), vgg_loss.data.item()\n",
        "\n",
        "    def _calc_gradient_penalty(self, clean_img, gen_img):\n",
        "        batch_size = clean_img.size()[0]\n",
        "        alpha = Variable(torch.rand(batch_size, 1))\n",
        "        alpha = alpha.expand(batch_size, clean_img.nelement(\n",
        "        ) // batch_size).contiguous().view(clean_img.size()).float()\n",
        "        if self.gpu:\n",
        "            alpha = alpha.cuda()\n",
        "\n",
        "        interpolates = (alpha * clean_img + (1 - alpha)\n",
        "                        * gen_img).requires_grad_(True)\n",
        "        disc_interpolates = self.discriminator(interpolates)\n",
        "        fake = Variable(torch.Tensor(batch_size, 1).fill_(1.0),\n",
        "                        requires_grad=False)\n",
        "        if self.gpu:\n",
        "            fake = fake.cuda()\n",
        "\n",
        "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                                  grad_outputs=fake, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "        # gradients = gradients.view(gradients.size(0), -1)\n",
        "        # print(gradients.size())\n",
        "        # print(torch.norm(gradients, 2, dim=1).size())\n",
        "\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        # print(\"gradient_penalty: \", gradient_penalty.cpu().item())\n",
        "        return gradient_penalty\n",
        "\n",
        "    def test(self, epoch):\n",
        "        timestr = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "        print(timestr)\n",
        "        # test set\n",
        "        total_mse_loss = 0\n",
        "        total_g_loss = 0\n",
        "        total_d_loss = 0\n",
        "        total_vgg_loss = 0\n",
        "        batch_num = 0\n",
        "        for batch_index, batch in enumerate(self.validDataloader):\n",
        "            clean_img = batch[\"clean_img\"]\n",
        "            noisy_img = batch[\"noisy_img\"]\n",
        "\n",
        "            loss = self._train_generator(clean_img, noisy_img, train=False)\n",
        "            # print(loss, end=\" ;\")\n",
        "            total_g_loss += loss[0]\n",
        "            total_mse_loss += loss[1]\n",
        "            total_d_loss += loss[2]\n",
        "            total_vgg_loss += loss[3]\n",
        "            batch_num += 1\n",
        "        mse_loss = total_mse_loss / batch_num\n",
        "        g_loss = total_g_loss / batch_num\n",
        "        d_loss = total_d_loss / batch_num\n",
        "        vgg_loss = total_vgg_loss / batch_num\n",
        "        print(\"%s Epoch： %d lr：%.10f Test Loss：g-loss: %.4f vgg-loss: %.4f mse-loss： %.4f d_loss: %.4f\" %\n",
        "                (self.v, epoch, self.G_optimizer.defaults[\"lr\"], g_loss, vgg_loss, mse_loss, d_loss))\n",
        "        # self.compute_quality()\n",
        "        self.save_loss((vgg_loss, mse_loss, g_loss, d_loss))\n",
        "        self.save_model()\n",
        "\n",
        "    def compute_quality(self):\n",
        "        psnr1 = 0\n",
        "        psnr2 = 0\n",
        "        mse1 = 0\n",
        "        mse2 = 0\n",
        "        ssim1 = 0\n",
        "        ssim2 = 0\n",
        "        _psnr1 = 0\n",
        "        _psnr2 = 0\n",
        "        _mse1 = 0\n",
        "        _mse2 = 0\n",
        "        _ssim1 = 0\n",
        "        _ssim2 = 0\n",
        "        for i in range(101, 111):\n",
        "            free_nii = nib.load(\"./data/dataset/Free/%d.nii\" % i)\n",
        "            noised_nii = nib.load(\n",
        "                \"./data/dataset/noise_%d/%d.nii\" % (self.level, i))\n",
        "\n",
        "            clean_img = free_nii.get_data()[:, :144, :].astype(np.int16)\n",
        "            noisy_img = noised_nii.get_data()[:, :144, :].astype(np.int16)\n",
        "            patchs, row, col = patch_test_img(noisy_img)\n",
        "            denoisy_img = merge_test_img(\n",
        "                self.denoising(patchs), row, col).astype(np.int16)\n",
        "\n",
        "            psnr1 += peak_signal_noise_ratio(clean_img, noisy_img, 4096)\n",
        "            psnr2 += peak_signal_noise_ratio(clean_img, denoisy_img, 4096)\n",
        "\n",
        "            mse1 += normalized_root_ms(clean_img, noisy_img)\n",
        "            mse2 += normalized_root_ms(clean_img, denoisy_img)\n",
        "\n",
        "            ssim1 += structural_similarity(clean_img, noisy_img,\n",
        "                                  data_range=4096, multichannel=True)\n",
        "            ssim2 += structural_similarity(clean_img, denoisy_img,\n",
        "                                  data_range=4096, multichannel=True)\n",
        "\n",
        "            max = np.max(clean_img)\n",
        "            _psnr1 += peak_signal_noise_ratio(clean_img, noisy_img, max)\n",
        "            _psnr2 += peak_signal_noise_ratio(clean_img, denoisy_img, max)\n",
        "\n",
        "            _mse1 += normalized_root_ms(clean_img, noisy_img)\n",
        "            _mse2 += normalized_root_ms(clean_img, denoisy_img)\n",
        "\n",
        "            _ssim1 += structural_similarity(clean_img, noisy_img,\n",
        "                                   data_range=max, multichannel=True)\n",
        "            _ssim2 += structural_similarity(clean_img, denoisy_img,\n",
        "                                   data_range=max, multichannel=True)\n",
        "        psnr1 *= 0.1\n",
        "        psnr2 *= 0.1\n",
        "        mse1 *= 0.1\n",
        "        mse2 *= 0.1\n",
        "        ssim1 *= 0.1\n",
        "        ssim2 *= 0.1\n",
        "\n",
        "        _psnr1 *= 0.1\n",
        "        _psnr2 *= 0.1\n",
        "        _mse1 *= 0.1\n",
        "        _mse2 *= 0.1\n",
        "        _ssim1 *= 0.1\n",
        "        _ssim2 *= 0.1\n",
        "        with open(\"./loss/\" + self.v + \"psnr.csv\", \"a+\") as f:\n",
        "            f.write(\"%f,%f,%f,%f,%f,%f\\n\" %\n",
        "                    (_psnr1, _psnr2, _ssim1, _ssim2, _mse1, _mse2))\n",
        "        timestr = time.strftime(\"%H:%M:%S\", time.localtime())\n",
        "        with open(\"./loss/\" + self.v + \"psnr_4096.csv\", \"a+\") as f:\n",
        "            f.write(\"%s: %.10f,%f,%f,%f,%f,%f,%f\\n\" %\n",
        "                    (timestr, self.lr, psnr1, psnr2, ssim1, ssim2, mse1, mse2))\n",
        "        print(\"psnr: %f,%f,ssim: %f,%f,mse:%f,%f\\n\" %\n",
        "              (_psnr1, _psnr2, _ssim1, _ssim2, _mse1, _mse2))\n",
        "\n",
        "    '''\n",
        "    N*H*W*D -> N*C*D*H*W\n",
        "    return: N*H*W*D\n",
        "    '''\n",
        "\n",
        "    def denoising(self, patchs):\n",
        "        n, h, w, d = patchs.shape\n",
        "        denoised_patchs = []\n",
        "        for i in range(0, n, self.batch_size):\n",
        "            batch = patchs[i:i + self.batch_size]\n",
        "            batch_size = batch.shape[0]\n",
        "            x = np.reshape(batch, (batch_size, 1, w, h, d))\n",
        "            x = x.transpose(0, 1, 4, 2, 3)\n",
        "            x = Variable(torch.from_numpy(x).float()).cuda()\n",
        "            y = self.generator(x)\n",
        "            denoised_patchs.append(y.cpu().data.numpy())\n",
        "        # print(len(denoised_patchs))\n",
        "        denoised_patchs = np.vstack(denoised_patchs)\n",
        "        # print(denoised_patchs.shape)\n",
        "        denoised_patchs = np.reshape(denoised_patchs, (n, d, h, w))\n",
        "        denoised_patchs = denoised_patchs.transpose(0, 2, 3, 1)\n",
        "        # print(denoised_patchs.shape)\n",
        "        return denoised_patchs\n",
        "\n",
        "    def save_model(self):\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.makedirs(self.save_dir)\n",
        "        torch.save(self.generator.state_dict(),\n",
        "                   self.save_dir + \"G_\" + self.v + \".pkl\")\n",
        "        torch.save(self.discriminator.state_dict(),\n",
        "                   self.save_dir + \"D_\" + self.v + \".pkl\")\n",
        "\n",
        "    def load_model(self):\n",
        "        if os.path.exists(self.save_dir + \"G_\" + self.v + \".pkl\") and \\\n",
        "                os.path.exists(self.save_dir + \"D_\" + self.v + \".pkl\"):\n",
        "\n",
        "            self.generator.load_state_dict(\n",
        "                torch.load(\n",
        "                    self.save_dir + \"G_\" + self.v + \".pkl\",\n",
        "                    map_location={'cuda:1': 'cuda:0'}))\n",
        "            self.discriminator.load_state_dict(\n",
        "                torch.load(\n",
        "                    self.save_dir + \"D_\" + self.v + \".pkl\",\n",
        "                    map_location={'cuda:1': 'cuda:0'}))\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def save_loss(self, loss):\n",
        "        value = \"\"\n",
        "        for item in loss:\n",
        "            value = value + str(item) + \",\"\n",
        "        value += \"\\n\"\n",
        "        with open(\"./loss/\" + self.v + \".csv\", \"a+\") as f:\n",
        "            f.write(value)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sVTpfdIEtpe"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import numpy as np\n",
        "\n",
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, path_to_data, split=\"train\"):\n",
        "        if split == \"train\":\n",
        "            split_indices = [*range(1, 101)]\n",
        "        elif split == \"test\":\n",
        "            split_indices = [*range(101, 111)]\n",
        "\n",
        "        print(f\"Start reading {split}ing dataset...\")\n",
        "\n",
        "        # read the first set of volumes\n",
        "        clean_mri_set = []\n",
        "        noisy_mri_set = []\n",
        "\n",
        "        for i in tqdm_notebook(split_indices):\n",
        "            # load the current volumes\n",
        "            clean_mri_temp = np.load(path_to_data / f\"data/{i}.npy\")\n",
        "            noisy_mri_temp = np.load(path_to_data / f\"noisy/{i}.npy\")\n",
        "\n",
        "            # append to the existing stack\n",
        "            clean_mri_set.append(clean_mri_temp)\n",
        "            noisy_mri_set.append(noisy_mri_temp)\n",
        "\n",
        "        self.clean_mri_set = clean_mri_set\n",
        "        self.noisy_mri_set = noisy_mri_set\n",
        "        self.arrshape0 = clean_mri_set[0].shape[0]\n",
        "        self.total = len(self.clean_mri_set) * self.arrshape0\n",
        "        self.current_patch = 1\n",
        "\n",
        "        print(len(self.clean_mri_set))\n",
        "        print(self.total)\n",
        "        print(f\"End reading {split}ing dataset...\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = index // self.arrshape0\n",
        "        y = index % self.arrshape0\n",
        "        clean_img = torch.from_numpy(self.clean_mri_set[x][y]).float().squeeze(axis=1)\n",
        "        noisy_img = torch.from_numpy(self.noisy_mri_set[x][y]).float().squeeze(axis=1)\n",
        "        return {\"clean_img\": clean_img, \"noisy_img\": noisy_img}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782,
          "referenced_widgets": [
            "8e3a19c2b8ef4987b03e1707fc2c543f",
            "3e6bbc3cff364dd59cefa6d7a92b164a",
            "7ce78a3651bf4c97b32988cce9332254",
            "4f6a00c5a9e04cbd9b60f9e837ed0290",
            "b9026923673b4e1d9d8ed11a449b4a95",
            "53ac1e81fabd4c71b65571bc0da092d6",
            "1eaa39742bd945cf9c87e70e06619d0d",
            "76125ec17d7a456fa576010fcd2dcab2",
            "237976c10cb64e01b01fae8e7aededa3",
            "bd20104fc7374f8b95c098fdba26bc39",
            "b3ca1ffe201941b38fcd9831daa83f62",
            "bdcd5afb38b64c8a8891a71a8eee8ec9",
            "64f5d443eed543f993fd7eaac3395138",
            "ec6394f021864bbbb9f21a952b9a0606",
            "dbca70dd8d964370b0afc180ce6ad22a",
            "a6014b56010a46ec9d2d0fc679c52108",
            "50252f999daf42ba8c5e4bd8e4f87a9c",
            "3f72bf69c85641589f8528d2b495fabe",
            "cbc1ee1fa9e14234abcf41098640a061",
            "f32abd0040074a21abe775b76d899df4",
            "0310da08f870404dbc14b5f5232ec402",
            "ee3d42708d804aafa65343d55dc98d1d"
          ]
        },
        "id": "XxhAkmqoO0C9",
        "outputId": "35e106b0-9c8e-4186-8136-7c85cc4e4ec4"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # torch.cuda.set_device(1)\n",
        "    path_to_data = Path(\"/content/drive/MyDrive/ED6001_MIA_Term_Project/patches\")\n",
        "    wgan = WGAN(path_to_data)\n",
        "    wgan.train()\n",
        "\n",
        "    # # valid\n",
        "    # for i in range(101, 111):\n",
        "\n",
        "    #     nii_img = nib.load(\"./data/dataset/noise_%d/%d.nii\" % (level, i))\n",
        "    #     x = nii_img.get_data()\n",
        "    #     patchs, row, col = patch_test_img(x)\n",
        "    #     print(patchs.shape)\n",
        "    #     denoised_img = merge_test_img(wgan.denoising(patchs), row, col)\n",
        "    #     print(denoised_img.shape)\n",
        "    #     denoised_img = denoised_img.astype(np.int16)\n",
        "\n",
        "    #     denoised_image = nib.Nifti1Image(\n",
        "    #         denoised_img, nii_img.affine, nii_img.header)\n",
        "    #     nib.save(denoised_image, \"./result/%d_wgan_vgg_mse_denoised_img%d.nii\" % (level, i))\n",
        "    # # print((x - denoised_img).mean())\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start reading training dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e3a19c2b8ef4987b03e1707fc2c543f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "78400\n",
            "End reading training dataset...\n",
            "Start reading testing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdcd5afb38b64c8a8891a71a8eee8ec9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "7840\n",
            "End reading testing dataset...\n",
            "04:29:02\n",
            "0_0_5_0 Epoch： 0 lr：0.0000050000 Test Loss：g-loss: 21.6713 vgg-loss: 216.7130 mse-loss： 44823.3824 d_loss: 0.0018\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 0, G-Loss:  (9.735098838806152, 0.021784570068120956, -0.026783157140016556, 9.740096926689148)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 1, G-Loss:  (9.646087646484375, 0.22660768032073975, -0.3204064965248108, 9.73988652229309)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 2, G-Loss:  (9.556740760803223, 0.4317483901977539, -0.6144554615020752, 9.739447832107544)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 3, G-Loss:  (9.466711044311523, 0.6378844976425171, -0.9098941683769226, 9.738721251487732)\n",
            "\tVGG_MSE - lr: 0.0000050000, Level: 0, Epoch: 0, bath_index: 0, iter: 4, G-Loss:  (9.375849723815918, 0.845659077167511, -1.2076265811920166, 9.737816452980042)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9a394cd44031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpath_to_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/ED6001_MIA_Term_Project/patches\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# # valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b22db005717a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# train generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoised_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0;31m# print(\"G Loss:%.4f, %.4f\" %\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;31m#    (float(loss[0]), float(loss[1])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b22db005717a>\u001b[0m in \u001b[0;36m_train_generator\u001b[0;34m(self, clean_img, noised_img, train)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# (self.lambda_mse * mse_loss).backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfake_validity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [110, 1, 6, 32, 32]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1mdT2ETROFv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}