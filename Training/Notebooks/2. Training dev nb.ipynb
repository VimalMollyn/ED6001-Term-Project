{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Vs9QqrGmL7vP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../../Training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Hov55xbhLfyY",
    "outputId": "351879bd-8f6c-41be-942c-6a3047bd9b07"
   },
   "outputs": [],
   "source": [
    "## imports go here\n",
    "import os\n",
    "import time\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity, normalized_root_mse\n",
    "\n",
    "import wandb\n",
    "\n",
    "from preprocessing import patch_test_img, merge_test_img\n",
    "# from data import MRIDataset ## imports for the MRI dataset\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvimaled17b055\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/vimaled17b055/mia_final/runs/29x9a5lo\" target=\"_blank\">northern-dream-3</a></strong> to <a href=\"https://wandb.ai/vimaled17b055/mia_final\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/vimaled17b055/mia_final/runs/29x9a5lo?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fdf3f40a940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"mia_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "Hov55xbhLfyY",
    "outputId": "351879bd-8f6c-41be-942c-6a3047bd9b07"
   },
   "outputs": [],
   "source": [
    "class GeneratorNet(nn.Module):\n",
    "    \"\"\" \n",
    "    In the original implementation, post-activation values were being added to pre-activation values \n",
    "    Modified it to add pre-activation values, then apply activation\n",
    "    Removed final ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(1, 32, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(32),)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True), nn.Conv3d(32, 64, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(64),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True), nn.Conv3d(64, 128, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(128),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True), nn.Conv3d(128, 256, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(256),\n",
    "        )\n",
    "\n",
    "        self.deConv1 = nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True), nn.Conv3d(256, 128, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(128),\n",
    "        )\n",
    "\n",
    "        self.deConv2 = nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True), nn.Conv3d(128, 64, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(64),\n",
    "        )\n",
    "\n",
    "        self.deConv3 = nn.Sequential(\n",
    "            nn.LeakyReLU(inplace=True), nn.Conv3d(64, 32, kernel_size=3, padding=1, bias=True), nn.BatchNorm3d(32),\n",
    "        )\n",
    "\n",
    "        self.deConv4 = nn.Sequential(nn.LeakyReLU(inplace=True), nn.Conv3d(32, 1, kernel_size=3, padding=1),)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "\n",
    "        out = self.deConv1(conv4)\n",
    "        out += conv3\n",
    "\n",
    "        out = self.deConv2(out)\n",
    "        out += conv2\n",
    "\n",
    "        out = self.deConv3(out)\n",
    "        out += conv1\n",
    "\n",
    "        out = self.deConv4(out)\n",
    "        out += x\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DiscriminatorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(1, 32, kernel_size=3, padding=1), nn.LeakyReLU(),)\n",
    "\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(32, 64, kernel_size=3, padding=1), nn.LeakyReLU(),)\n",
    "\n",
    "        self.conv3 = nn.Sequential(nn.Conv3d(64, 128, kernel_size=3, padding=1), nn.LeakyReLU(),)\n",
    "\n",
    "        self.fc = nn.Linear(128 * 6 * 32 * 32, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        output = self.fc(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for i in size:\n",
    "            num_features *= i\n",
    "\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class VGG19(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19, self).__init__()\n",
    "        vgg19 = models.vgg19(pretrained=True)\n",
    "        self.feature = vgg19.features\n",
    "    '''\n",
    "    input: N*1*D(6)*H*W\n",
    "    output: N*C*H*W\n",
    "    '''\n",
    "\n",
    "    def forward(self, input):\n",
    "        # VGG19: means:103.939, 116.779, 123.68\n",
    "        input /= 16\n",
    "        depth = input.size()[2]\n",
    "        result = []\n",
    "        for i in range(depth):\n",
    "            x = torch.cat(\n",
    "                (input[:, :, i, :, :] - 103.939, input[:, :, i, :, :] - 116.779, input[:, :, i, :, :] - 123.68), 1)\n",
    "            result.append(self.feature(x))\n",
    "\n",
    "        output = torch.cat(result, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ohdln8DRMoJW"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv3d) or isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm3d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "k8BYcjNmOLO_"
   },
   "outputs": [],
   "source": [
    "class WGAN():\n",
    "    def __init__(self, level=0):\n",
    "        # parameters\n",
    "        self.epochs = 10\n",
    "        self.batch_size = 64\n",
    "        self.lr =5e-6\n",
    "\n",
    "        self.d_iter = 5\n",
    "        self.lambda_gp = 10\n",
    "\n",
    "        self.lambda_vgg = 1e-1\n",
    "        self.lambda_d = 1e-3\n",
    "        self.lambda_mse = 1\n",
    "\n",
    "        self.level = level\n",
    "\n",
    "        self.loss_dir = \"./loss/\"\n",
    "        self.v = \"0_0_5_%d\" % self.level  # vs\n",
    "        self.save_dir = \"./model/\" + self.v + \"/\"\n",
    "        Path(self.loss_dir).mkdir(parents=True, exist_ok=True)\n",
    "        Path(self.save_dir).mkdir(parents=True, exist_ok=True)\n",
    "        self.gpu = False\n",
    "\n",
    "        self.generator = GeneratorNet()\n",
    "        self.discriminator = DiscriminatorNet()\n",
    "        self.vgg19 = VGG19()\n",
    "\n",
    "        self.G_optimizer = optim.Adam(\n",
    "            self.generator.parameters(), lr=self.lr, betas=(0.5, 0.9))\n",
    "        self.D_optimizer = optim.Adam(\n",
    "            self.discriminator.parameters(), lr=self.lr, betas=(0.5, 0.9))\n",
    "\n",
    "        self.G_loss = nn.MSELoss()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.generator.cuda()\n",
    "            self.discriminator.cuda()\n",
    "            self.vgg19.cuda()\n",
    "            self.gpu = True\n",
    "        if not self.load_model():\n",
    "            initialize_weights(self.generator)\n",
    "            initialize_weights(self.discriminator)\n",
    "\n",
    "    def train(self, trainloader, validloader):\n",
    "        self.dataloader = trainloader\n",
    "        self.validDataloader = validloader\n",
    "        examples_seen = 0\n",
    "\n",
    "        ## training loop\n",
    "        for epoch in range(0, self.epochs):\n",
    "\n",
    "            # iterate over the dataset\n",
    "            pbar = tqdm.tqdm(total=len(self.dataloader))\n",
    "            pbar.set_description(f\"Epoch {epoch}\")\n",
    "            \n",
    "            for batch_index, batch in enumerate(self.dataloader):\n",
    "                clean_img = batch[\"clean_img\"]\n",
    "                noised_img = batch[\"noisy_img\"]\n",
    "                \n",
    "                examples_seen += clean_img.shape[0]\n",
    "\n",
    "                # train discriminator\n",
    "                for iter_i in range(self.d_iter):\n",
    "                    loss = self._train_discriminator(clean_img, noised_img)\n",
    "\n",
    "                wandb.log({\n",
    "                    \"discriminator_loss\": loss[0],\n",
    "                    \"neg_real_validity\": loss[1],\n",
    "                    \"fake_validity\": loss[2],\n",
    "                    \"gradient_penalty\": loss[3],\n",
    "                    \"examples_seen\": examples_seen\n",
    "                })\n",
    "\n",
    "                # train generator\n",
    "                loss = self._train_generator(clean_img, noised_img)\n",
    "\n",
    "                wandb.log({\n",
    "                    \"generator_loss\": loss[0],\n",
    "                    \"mse_loss\": loss[1],\n",
    "                    \"neg_fake_validity\": loss[2],\n",
    "                    \"perceptual_loss\": loss[3],\n",
    "                    \"examples_seen\": examples_seen\n",
    "                })\n",
    "\n",
    "\n",
    "                # save model and loss\n",
    "                if batch_index % 100 == 0:\n",
    "                    self.save_model()\n",
    "                \n",
    "                # update pbar\n",
    "                loss = [0]\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(loss=loss[0])\n",
    "                with torch.no_grad():\n",
    "                    self.visualize_denoised()\n",
    "\n",
    "\n",
    "            if ((epoch + 1) % 4 == 0 and self.lr > 1e-7):\n",
    "                self.G_optimizer.defaults[\"lr\"] *= 0.5\n",
    "                self.G_optimizer.defaults[\"lr\"] *= 0.5\n",
    "                self.lr *= 0.5\n",
    "\n",
    "            pbar.close()\n",
    "            with torch.no_grad():\n",
    "                self.test(examples_seen)\n",
    "\n",
    "\n",
    "    def _train_discriminator(self, clean_img, noised_img, train=True):\n",
    "        self.D_optimizer.zero_grad()\n",
    "\n",
    "        z = Variable(noised_img)\n",
    "        real_img = Variable(clean_img / 4096)\n",
    "        if self.gpu:\n",
    "            z = z.cuda()\n",
    "            real_img = real_img.cuda()\n",
    "\n",
    "        fake_img = self.generator(z)\n",
    "        real_validity = self.discriminator(real_img)\n",
    "        fake_validity = self.discriminator(fake_img.data / 4096)\n",
    "        gradient_penalty = self._calc_gradient_penalty(\n",
    "            real_img.data, fake_img.data)\n",
    "\n",
    "        d_loss = torch.mean(-real_validity) + torch.mean(fake_validity) + \\\n",
    "            self.lambda_gp * gradient_penalty\n",
    "        if train:\n",
    "            d_loss.backward()\n",
    "            self.D_optimizer.step()\n",
    "\n",
    "        return d_loss.data.item(), torch.mean(-real_validity).cpu().item(), torch.mean(fake_validity).cpu().item(), self.lambda_gp * gradient_penalty.cpu().item()\n",
    "\n",
    "    def _train_generator(self, clean_img, noised_img, train=True):\n",
    "        z = Variable(noised_img)\n",
    "        real_img = Variable(clean_img, requires_grad=False)\n",
    "\n",
    "\n",
    "        if self.gpu:\n",
    "            z = z.cuda()\n",
    "            real_img = real_img.cuda()\n",
    "\n",
    "        self.G_optimizer.zero_grad()\n",
    "        self.D_optimizer.zero_grad()\n",
    "        self.vgg19.zero_grad()\n",
    "\n",
    "        criterion_mse = nn.MSELoss()\n",
    "        criterion_vgg= nn.MSELoss()\n",
    "\n",
    "        fake_img = self.generator(z)\n",
    "        mse_loss = criterion_mse(fake_img, real_img)\n",
    "        if train:\n",
    "            (self.lambda_mse * mse_loss).backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        feature_fake_vgg = self.vgg19(fake_img)\n",
    "        feature_real_vgg = Variable(self.vgg19(real_img).data, requires_grad=False).cuda()\n",
    "\n",
    "        vgg_loss = criterion_vgg(feature_fake_vgg, feature_real_vgg)\n",
    "\n",
    "        fake_validity = self.discriminator(fake_img / 4096)\n",
    "        g_loss =  self.lambda_vgg * vgg_loss + self.lambda_d * torch.mean(-fake_validity)\n",
    "\n",
    "        if train:\n",
    "            g_loss.backward()\n",
    "            self.G_optimizer.step()\n",
    "        return g_loss.data.item(), mse_loss.data.item(), torch.mean(-fake_validity).data.item(), vgg_loss.data.item()\n",
    "\n",
    "    def _calc_gradient_penalty(self, clean_img, gen_img):\n",
    "        batch_size = clean_img.size()[0]\n",
    "        alpha = Variable(torch.rand(batch_size, 1))\n",
    "        alpha = alpha.expand(batch_size, clean_img.nelement(\n",
    "        ) // batch_size).contiguous().view(clean_img.size()).float()\n",
    "        if self.gpu:\n",
    "            alpha = alpha.cuda()\n",
    "\n",
    "        interpolates = (alpha * clean_img + (1 - alpha)\n",
    "                        * gen_img).requires_grad_(True)\n",
    "        disc_interpolates = self.discriminator(interpolates)\n",
    "        fake = Variable(torch.Tensor(batch_size, 1).fill_(1.0),\n",
    "                        requires_grad=False)\n",
    "        if self.gpu:\n",
    "            fake = fake.cuda()\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                                  grad_outputs=fake, create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        return gradient_penalty\n",
    "\n",
    "    def test(self, examples_seen):\n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "        \n",
    "        timestr = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "        # print(timestr)\n",
    "\n",
    "        # test set\n",
    "        total_mse_loss = 0\n",
    "        total_g_loss = 0\n",
    "        total_d_loss = 0\n",
    "        total_vgg_loss = 0\n",
    "        batch_num = 0\n",
    "        for batch_index, batch in enumerate(self.validDataloader):\n",
    "            clean_img = batch[\"clean_img\"]\n",
    "            noisy_img = batch[\"noisy_img\"]\n",
    "\n",
    "            loss = self._train_generator(clean_img, noisy_img, train=False)\n",
    "            total_g_loss += loss[0]\n",
    "            total_mse_loss += loss[1]\n",
    "            total_d_loss += loss[2]\n",
    "            total_vgg_loss += loss[3]\n",
    "            batch_num += 1\n",
    "        mse_loss = total_mse_loss / batch_num\n",
    "        g_loss = total_g_loss / batch_num\n",
    "        d_loss = total_d_loss / batch_num\n",
    "        vgg_loss = total_vgg_loss / batch_num\n",
    "\n",
    "        wandb.log({\n",
    "            \"test_discriminator_loss\": d_loss,\n",
    "            \"test_generator_loss\": g_loss,\n",
    "            \"test_perceptual_loss\": vgg_loss,\n",
    "            \"test_mse_loss\": mse_loss,\n",
    "            \"examples_seen\": examples_seen\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # self.compute_quality()\n",
    "        self.save_loss((vgg_loss, mse_loss, g_loss, d_loss))\n",
    "        self.save_model()\n",
    "\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "    def visualize_denoised(self):\n",
    "        denoised = defaultdict(list)\n",
    "        \n",
    "        for batch_index, batch in enumerate(self.validDataloader):\n",
    "            clean_img = batch[\"clean_img\"]\n",
    "            noised_img = batch[\"noisy_img\"]\n",
    "            \n",
    "            if self.gpu:\n",
    "                noised_img = noised_img.cuda()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                denoised_img = self.generator(noised_img)\n",
    "                denoised[\"clean\"].append(clean_img[:, :, 3])\n",
    "                denoised[\"denoised\"].append(denoised_img[:, :, 3])\n",
    "                denoised[\"noisy\"].append(noised_img[:, :, 3])\n",
    "            break\n",
    "            \n",
    "        \n",
    "        # denoised is a list of denoised patches\n",
    "        # now take a sample slice from each patch and plot\n",
    "        clean_img_grid = torchvision.utils.make_grid(denoised[\"clean\"][0])\n",
    "        noisy_img_grid = torchvision.utils.make_grid(denoised[\"noisy\"][0])\n",
    "        denoised_img_grid = torchvision.utils.make_grid(denoised[\"denoised\"][0])\n",
    "        \n",
    "        # show(clean_img_grid)\n",
    "        # show(noisy_img_grid)\n",
    "        # show(denoised_img_grid)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"Clean Images\": wandb.Image(clean_img_grid),\n",
    "            \"Noisy Images\": wandb.Image(noisy_img_grid),\n",
    "            \"Denoised Images\": wandb.Image(denoised_img_grid)\n",
    "        })\n",
    "        \n",
    "    def compute_quality(self):\n",
    "        psnr1 = 0\n",
    "        psnr2 = 0\n",
    "        mse1 = 0\n",
    "        mse2 = 0\n",
    "        ssim1 = 0\n",
    "        ssim2 = 0\n",
    "        _psnr1 = 0\n",
    "        _psnr2 = 0\n",
    "        _mse1 = 0\n",
    "        _mse2 = 0\n",
    "        _ssim1 = 0\n",
    "        _ssim2 = 0\n",
    "\n",
    "        for i in range(101, 111):\n",
    "            # read a clean image and it's noisy counterpart,\n",
    "            # convert noisy image into it's patches and obtain a cleaned image\n",
    "            # merge the patches together\n",
    "            # compute metrics\n",
    "            \n",
    "            clean_mri = np.load(path_to_data / f\"data/{i}.npy\").squeeze(axis=1) ## shape (784, 1, 6, 32, 32)\n",
    "            noisy_mri = np.load(path_to_data / f\"noisy/{i}.npy\").squeeze(axis=1)\n",
    "            \n",
    "            # pass the noisy_mri through the generator\n",
    "            with torch.no_grad():\n",
    "                denoised = self.generator(noisy_mri)\n",
    "                \n",
    "            \n",
    "#             patchs, row, col = patch_test_img(noisy_img)\n",
    "#             denoisy_img = merge_test_img(\n",
    "#                 self.denoising(patchs), row, col).astype(np.int16)\n",
    "\n",
    "            psnr1 += peak_signal_noise_ratio(clean_img, noisy_img, 4096)\n",
    "            psnr2 += peak_signal_noise_ratio(clean_img, denoisy_img, 4096)\n",
    "\n",
    "            mse1 += normalized_root_ms(clean_img, noisy_img)\n",
    "            mse2 += normalized_root_ms(clean_img, denoisy_img)\n",
    "\n",
    "            ssim1 += structural_similarity(clean_img, noisy_img,\n",
    "                                  data_range=4096, multichannel=True)\n",
    "            ssim2 += structural_similarity(clean_img, denoisy_img,\n",
    "                                  data_range=4096, multichannel=True)\n",
    "\n",
    "            max = np.max(clean_img)\n",
    "            _psnr1 += peak_signal_noise_ratio(clean_img, noisy_img, max)\n",
    "            _psnr2 += peak_signal_noise_ratio(clean_img, denoisy_img, max)\n",
    "\n",
    "            _mse1 += normalized_root_ms(clean_img, noisy_img)\n",
    "            _mse2 += normalized_root_ms(clean_img, denoisy_img)\n",
    "\n",
    "            _ssim1 += structural_similarity(clean_img, noisy_img,\n",
    "                                   data_range=max, multichannel=True)\n",
    "            _ssim2 += structural_similarity(clean_img, denoisy_img,\n",
    "                                   data_range=max, multichannel=True)\n",
    "            \n",
    "        psnr1 *= 0.1\n",
    "        psnr2 *= 0.1\n",
    "        mse1 *= 0.1\n",
    "        mse2 *= 0.1\n",
    "        ssim1 *= 0.1\n",
    "        ssim2 *= 0.1\n",
    "\n",
    "        _psnr1 *= 0.1\n",
    "        _psnr2 *= 0.1\n",
    "        _mse1 *= 0.1\n",
    "        _mse2 *= 0.1\n",
    "        _ssim1 *= 0.1\n",
    "        _ssim2 *= 0.1\n",
    "        with open(\"./loss/\" + self.v + \"psnr.csv\", \"a+\") as f:\n",
    "            f.write(\"%f,%f,%f,%f,%f,%f\\n\" %\n",
    "                    (_psnr1, _psnr2, _ssim1, _ssim2, _mse1, _mse2))\n",
    "        timestr = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "        with open(\"./loss/\" + self.v + \"psnr_4096.csv\", \"a+\") as f:\n",
    "            f.write(\"%s: %.10f,%f,%f,%f,%f,%f,%f\\n\" %\n",
    "                    (timestr, self.lr, psnr1, psnr2, ssim1, ssim2, mse1, mse2))\n",
    "        print(\"psnr: %f,%f,ssim: %f,%f,mse:%f,%f\\n\" %\n",
    "              (_psnr1, _psnr2, _ssim1, _ssim2, _mse1, _mse2))\n",
    "\n",
    "    '''\n",
    "    N*H*W*D -> N*C*D*H*W\n",
    "    return: N*H*W*D\n",
    "    '''\n",
    "\n",
    "#     def denoising(self, patchs):\n",
    "#         n, h, w, d = patchs.shape\n",
    "#         denoised_patchs = []\n",
    "#         for i in range(0, n, self.batch_size):\n",
    "#             batch = patchs[i:i + self.batch_size]\n",
    "#             batch_size = batch.shape[0]\n",
    "#             x = np.reshape(batch, (batch_size, 1, w, h, d))\n",
    "#             x = x.transpose(0, 1, 4, 2, 3)\n",
    "#             x = Variable(torch.from_numpy(x).float()).cuda()\n",
    "#             y = self.generator(x)\n",
    "#             denoised_patchs.append(y.cpu().data.numpy())\n",
    "\n",
    "#         denoised_patchs = np.vstack(denoised_patchs)\n",
    "#         denoised_patchs = np.reshape(denoised_patchs, (n, d, h, w))\n",
    "#         denoised_patchs = denoised_patchs.transpose(0, 2, 3, 1)\n",
    "#         return denoised_patchs\n",
    "\n",
    "    def save_model(self):\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "        torch.save(self.generator.state_dict(),\n",
    "                   self.save_dir + \"G_\" + self.v + \".pkl\")\n",
    "        torch.save(self.discriminator.state_dict(),\n",
    "                   self.save_dir + \"D_\" + self.v + \".pkl\")\n",
    "\n",
    "    def load_model(self):\n",
    "        if os.path.exists(self.save_dir + \"G_\" + self.v + \".pkl\") and \\\n",
    "                os.path.exists(self.save_dir + \"D_\" + self.v + \".pkl\"):\n",
    "\n",
    "            self.generator.load_state_dict(\n",
    "                torch.load(self.save_dir + \"G_\" + self.v + \".pkl\")\n",
    "            )\n",
    "            self.discriminator.load_state_dict(\n",
    "                torch.load(self.save_dir + \"D_\" + self.v + \".pkl\")\n",
    "            )\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def save_loss(self, loss):\n",
    "        value = \"\"\n",
    "        for item in loss:\n",
    "            value = value + str(item) + \",\"\n",
    "        value += \"\\n\"\n",
    "        with open(\"./loss/\" + self.v + \".csv\", \"a+\") as f:\n",
    "            f.write(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2sVTpfdIEtpe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import numpy as np\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, path_to_data, split=\"train\"):\n",
    "        if split == \"train\":\n",
    "            split_indices = [*range(1, 101)]\n",
    "        elif split == \"test\":\n",
    "            split_indices = [*range(101, 111)]\n",
    "\n",
    "        print(f\"Start reading {split}ing dataset...\")\n",
    "\n",
    "        # read the first set of volumes\n",
    "        clean_mri_set = []\n",
    "        noisy_mri_set = []\n",
    "\n",
    "        for i in tqdm_notebook(split_indices):\n",
    "            # load the current volumes\n",
    "            clean_mri_temp = np.load(path_to_data / f\"data/{i}.npy\").squeeze(axis=1)\n",
    "            noisy_mri_temp = np.load(path_to_data / f\"noisy/{i}.npy\").squeeze(axis=1)\n",
    "\n",
    "            # append to the existing stack\n",
    "            clean_mri_set.append(clean_mri_temp)\n",
    "            noisy_mri_set.append(noisy_mri_temp)\n",
    "\n",
    "        self.clean_mri_set = np.concatenate(clean_mri_set, axis=0)\n",
    "        self.noisy_mri_set = np.concatenate(noisy_mri_set, axis=0)\n",
    "        # self.arrshape0 = clean_mri_set[0].shape[0]\n",
    "        # self.total = len(self.clean_mri_set) * self.arrshape0\n",
    "        self.total = self.clean_mri_set.shape[0]\n",
    "        self.current_patch = 1\n",
    "\n",
    "        print(len(self.clean_mri_set))\n",
    "        print(self.total)\n",
    "        print(f\"End reading {split}ing dataset...\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # x = index // self.arrshape0\n",
    "        # y = index % self.arrshape0\n",
    "        # clean_img = torch.from_numpy(self.clean_mri_set[x][y]).float().squeeze(axis=1)\n",
    "        # noisy_img = torch.from_numpy(self.noisy_mri_set[x][y]).float().squeeze(axis=1)\n",
    "        \n",
    "        clean_img = torch.from_numpy(self.clean_mri_set[index]).float()\n",
    "        noisy_img = torch.from_numpy(self.noisy_mri_set[index]).float()\n",
    "        return {\"clean_img\": clean_img, \"noisy_img\": noisy_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "XxhAkmqoO0C9",
    "outputId": "c96a3968-f907-46d2-94fe-3b45e3183b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading training dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54dbd977fe6483495863fd489453efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78400\n",
      "78400\n",
      "End reading training dataset...\n",
      "Start reading testing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935d954fe15f42f2960d499f9ab242b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7840\n",
      "7840\n",
      "End reading testing dataset...\n"
     ]
    }
   ],
   "source": [
    "path_to_data = Path(\"../../patches/\")\n",
    "\n",
    "trainset = MRIDataset(path_to_data=path_to_data, split=\"train\")\n",
    "validset = MRIDataset(path_to_data=path_to_data, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "XxhAkmqoO0C9",
    "outputId": "c96a3968-f907-46d2-94fe-3b45e3183b12"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a6b159f9b6419d92d3daa6bfe93bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10562/594160101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# # valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10562/3377868939.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainloader, validloader)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# train discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0miter_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoised_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 wandb.log({\n",
      "\u001b[0;32m/tmp/ipykernel_10562/3377868939.py\u001b[0m in \u001b[0;36m_train_discriminator\u001b[0;34m(self, clean_img, noised_img, train)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreal_validity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_validity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_gp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoised_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wgan = WGAN()\n",
    "trainloader = DataLoader(trainset, batch_size=wgan.batch_size, shuffle=True)\n",
    "validloader = DataLoader(validset, batch_size=wgan.batch_size, shuffle=True)\n",
    "wgan.train(trainloader, validloader)\n",
    "\n",
    "    # # valid\n",
    "    # for i in range(101, 111):\n",
    "\n",
    "    #     nii_img = nib.load(\"./data/dataset/noise_%d/%d.nii\" % (level, i))\n",
    "    #     x = nii_img.get_data()\n",
    "    #     patchs, row, col = patch_test_img(x)\n",
    "    #     print(patchs.shape)\n",
    "    #     denoised_img = merge_test_img(wgan.denoising(patchs), row, col)\n",
    "    #     print(denoised_img.shape)\n",
    "    #     denoised_img = denoised_img.astype(np.int16)\n",
    "\n",
    "    #     denoised_image = nib.Nifti1Image(\n",
    "    #         denoised_img, nii_img.affine, nii_img.header)\n",
    "    #     nib.save(denoised_image, \"./result/%d_wgan_vgg_mse_denoised_img%d.nii\" % (level, i))\n",
    "    # # print((x - denoised_img).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "2. Training dev nb.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
